{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb86n-BbXM1N"
   },
   "source": [
    "# Рекомендательные системы\n",
    "## Урок 1. Введение, примеры задач, бизнес- и ML-метрики\n",
    "### Практическое задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Сравните метрики hit_rate@k, precision@k. Какую метрику использовать предпочтительно и почему. Привидите пример 2-3 задач (опишите, что является клиентом, что товаром), в которой более уместно использовать метрику hit_rate?**  \n",
    "\n",
    "Роль алгоритма ранжирования (часто называемого системой рекомендаций) состоит в том, чтобы вернуть пользователю набор соответствующих элементов или документов на основе некоторых обучающих данных. Определение релевантности может варьироваться и обычно зависит от приложения. Метрики системы ранжирования направлены на количественную оценку эффективности этих рейтингов или рекомендаций в различных контекстах. Некоторые показатели сравнивают набор рекомендуемых документов с базовым набором соответствующих документов, в то время как другие показатели могут явно включать числовые рейтинги.  \n",
    "\n",
    "Целью системы ранжирования является создание наиболее подходящей выборки для каждого пользователя. Актуальность наборов и эффективность алгоритмов можно измерить с помощью метрик, перечисленных ниже.\n",
    "\n",
    "**Hit rate**, как и полнота(recall) - показывает, как много объектов класса 1 находит классификатор или другими словами отражает какой процент объектов положительного класса мы правильно классифицировали (был ли хотя бы 1 релевантный товар среди рекомендованных), а **hit_rate@k** - был ли хотя бы 1 релевантный товар среди топ-k рекомендованных.\n",
    "Например, нам необходимо понять, насколько хороши наши топ-10 рекомендаций. Для оценки топ-10 мы используем показатель попадания, то есть, если пользователь оценил один из 10 лучших, которые мы рекомендовали, мы считаем это «попаданием».\n",
    "\n",
    "Общая частота попаданий в систему - это количество попаданий, разделенное на количество тестовых пользователей. Он измеряет, как часто мы можем рекомендовать удаленный рейтинг, чем выше, тем лучше. Очень низкий процент попаданий часто означает, что у нас недостаточно данных для работы.\n",
    "\n",
    "Точность(precision) - показывает, насколько мы можем доверять классификатору, если он выдаёт ответ – 1 или какой процент рекомендованных товаров приобрел пользователь/покупатель. Чем выше точность, тем меньше ложных срабатываний. **Precision@k** - это мера того, сколько из первых k рекомендованных выборок входит в набор действительно релевантных, усредненных по всем пользователям. В этой метрике не учитывается порядок рекомендаций.\n",
    "\n",
    "Пример 1(hit_rate@k): Рекомендация категории товаров, например, автомобили, яхты, квартиры. Пользователь - клиент, категория - товар.  \n",
    "Пример 2(hit_rate@k): Рекомендации дополнительных товаров к текущей покупке. Если человек покупает кровать, то автоматически рекомендуем ему несколько видов подходящих к нему матрасов. Пользователь - клиент, товар - товар.  \n",
    "Пример 3(hit_rate@k): Поиск дешёвых авиабилетов. Пользователь - клиент, авиабилет - товар.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) В метрике NDCG@k мы используем логарифм в знаменателе. Как Вы думаете, почему именно логарифм? Какую функцию можно использовать вместо логарифма? Привидите пример метрик/подходов к предобработке данных/функций ошибок в ML, где также в знаменателе присутствует логарифм.**  \n",
    "\n",
    "Предпосылка DCG заключается в том, что высокорелевантные документы, появляющиеся ниже в списке результатов поиска, должны подвергаться штрафу, поскольку оцененное значение релевантности уменьшается логарифмически пропорционально позиции результата.  \n",
    "\n",
    "Традиционная формула DCG, накопленная на определенной позиции ранга, определяется как: \n",
    "![image](DCG1.png) \n",
    "\n",
    "Ранее не было теоретически обоснованного обоснования использования логарифмического коэффициента уменьшения, кроме того факта, что он обеспечивает плавное уменьшение. Но авторы дают теоретическую гарантию использования коэффициента логарифмического сокращения в нормализованном DCG (NDCG). Авторы показывают, что для каждой пары существенно различных функций ранжирования NDCG может согласованно решать, какая из них лучше.  \n",
    "Альтернативная формулировка DCG делает больший упор на поиск соответствующих документов:  \n",
    "![image](DCG2.png)\n",
    "Последняя формула обычно используется в промышленности, включая крупные поисковые компании и платформы для соревнований по науке о данных, такие как Kaggle.  \n",
    "\n",
    "Списки результатов поиска различаются по длине в зависимости от запроса . Сравнение производительности поисковой системы от одного запроса к другому не может быть последовательно достигнуто с использованием только DCG, поэтому совокупный выигрыш в каждой позиции для выбранного значения должен быть нормализован по запросам. Это делается путем сортировки всех соответствующих документов в корпусе по их относительной релевантности, что позволяет получить максимально возможную DCG через позицию , также называемую идеальной DCG (IDCG) через эту позицию. Для запроса нормализованная дисконтированная совокупная выгода , или nDCG, вычисляется как: \n",
    "![image](nDCG1.png) \n",
    "где IDCG - идеальная дисконтированная совокупная прибыль, \n",
    "![image](IDCG.png) \n",
    "и представляет собой список релевантных документов (упорядоченный по их релевантности) в корпусе до позиции p.  \n",
    "Значения nDCG для всех запросов можно усреднить, чтобы получить меру средней производительности алгоритма ранжирования поисковой системы. Обратите внимание, что в идеальном алгоритме ранжирования будет то же самое, что и при создании nDCG 1,0. Тогда все вычисления nDCG являются относительными значениями в интервале от 0,0 до 1,0 и, следовательно, сопоставимы с перекрестными запросами.  \n",
    "Основная трудность, возникающая при использовании nDCG, заключается в отсутствии идеального упорядочивания результатов, когда доступна только частичная обратная связь по релевантности.  \n",
    "\n",
    "Пример:  \n",
    "В ответ на поисковый запрос участнику эксперимента предоставляется список документов, и его просят оценить релевантность каждого документа запросу. Каждый документ оценивается по шкале от 0 до 3, где 0 означает нерелевантность, 3 означает высокую актуальность, а 1 и 2 означают «где-то посередине». Для документов, упорядоченных алгоритмом ранжирования как \n",
    "![image](Dn.png)\n",
    "пользователь выставляет следующие оценки релевантности:  \n",
    "**3, 2, 3, 0, 1, 2**  \n",
    "То есть: документ 1 имеет релевантность 3, документ 2 имеет релевантность 2 и т. Д. Совокупный выигрыш этого списка результатов поиска составляет:  \n",
    "![image](CG6.png)  \n",
    "Изменение порядка любых двух документов не влияет на показатель CG. Если поменять местами и , то CG останется прежним, 11. DCG используется для выделения наиболее релевантных документов, появляющихся в начале списка результатов. Используя логарифмическую шкалу для сокращения, DCG для каждого результата в следующем порядке: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table class=\"wikitable\" border=\"1\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<th>\n",
    "<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle i}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mi>я</mi>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\ displaystyle i}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/add78d8608ad86e54951b8c8bd6c8d8416533d20\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.338ex; width:0.802ex; height:2.176ex;\" alt=\"я\"></span>\n",
    "</th>\n",
    "<th>\n",
    "<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle rel_{i}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mi>р</mi>\n",
    "        <mi>е</mi>\n",
    "        <msub>\n",
    "          <mi>л</mi>\n",
    "          <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "            <mi>я</mi>\n",
    "          </mrow>\n",
    "        </msub>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\ displaystyle rel_ {i}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/bfa59c4b006428f714ff913dea43de3a51717634\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.671ex; width:3.625ex; height:2.509ex;\" alt=\"rel _ {{i}}\"></span>\n",
    "</th>\n",
    "<th>\n",
    "<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle \\log _{2}(i+1)}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <msub>\n",
    "          <mi>журнал</mi>\n",
    "          <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "            <mn>2</mn>\n",
    "          </mrow>\n",
    "        </msub>\n",
    "        <mo>⁡</mo>\n",
    "        <mo stretchy=\"false\">(</mo>\n",
    "        <mi>я</mi>\n",
    "        <mo>+</mo>\n",
    "        <mn>1</mn>\n",
    "        <mo stretchy=\"false\">)</mo>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\ Displaystyle \\ журнал _ {2} (я + 1)}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/42c489d81e395765b11e9a6029b1d8dde8661d7c\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.838ex; width:10.641ex; height:2.843ex;\" alt=\"{\\ Displaystyle \\ журнал _ {2} (я + 1)}\"></span>\n",
    "</th>\n",
    "<th>\n",
    "<span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {rel_{i}}{\\log _{2}(i+1)}}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi>р</mi>\n",
    "              <mi>е</mi>\n",
    "              <msub>\n",
    "                <mi>л</mi>\n",
    "                <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                  <mi>я</mi>\n",
    "                </mrow>\n",
    "              </msub>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <msub>\n",
    "                <mi>журнал</mi>\n",
    "                <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                  <mn>2</mn>\n",
    "                </mrow>\n",
    "              </msub>\n",
    "              <mo>⁡</mo>\n",
    "              <mo stretchy=\"false\">(</mo>\n",
    "              <mi>я</mi>\n",
    "              <mo>+</mo>\n",
    "              <mn>1</mn>\n",
    "              <mo stretchy=\"false\">)</mo>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\ displaystyle {\\ frac {rel_ {i}} {\\ log _ {2} (я + 1)}}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/574fb7d7eef69865f521672d6dd04d24f2554e7c\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.671ex; width:11.477ex; height:6.176ex;\" alt=\"{\\ displaystyle {\\ frac {rel_ {i}} {\\ log _ {2} (я + 1)}}}\"></span>\n",
    "</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>1\n",
    "</td>\n",
    "<td>3\n",
    "</td>\n",
    "<td>1\n",
    "</td>\n",
    "<td>3\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>2\n",
    "</td>\n",
    "<td>2\n",
    "</td>\n",
    "<td>1,585\n",
    "</td>\n",
    "<td>1,262\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>3\n",
    "</td>\n",
    "<td>3\n",
    "</td>\n",
    "<td>2\n",
    "</td>\n",
    "<td>1.5\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>4\n",
    "</td>\n",
    "<td>0\n",
    "</td>\n",
    "<td>2.322\n",
    "</td>\n",
    "<td>0\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>5\n",
    "</td>\n",
    "<td>1\n",
    "</td>\n",
    "<td>2,585\n",
    "</td>\n",
    "<td>0,387\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>6\n",
    "</td>\n",
    "<td>2\n",
    "</td>\n",
    "<td>2,807\n",
    "</td>\n",
    "<td>0,712\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, рейтинг этого рейтинга:  \n",
    "![image](DCG6.png)  \n",
    "\n",
    "Теперь переключение на и приводит к сокращению DCG, поскольку менее релевантный документ занимает более высокое место в рейтинге; то есть более релевантный документ больше обесценивается, будучи помещенным в более низкий ранг.   \n",
    "\n",
    "Производительность этого запроса с другим запросом в этой форме несопоставима, поскольку другой запрос может иметь больше результатов, что приводит к большему общему DCG, который необязательно может быть лучше. Для сравнения значения DCG должны быть нормализованы.  \n",
    "\n",
    "Чтобы нормализовать значения DCG, необходим идеальный порядок для данного запроса. В этом примере это упорядочение будет монотонно убывающим видом всех известных оценок релевантности. В дополнение к шести из этого эксперимента, предположим, мы также знаем, что существует документ с уровнем релевантности 3 для того же запроса и документ со степенью релевантности 2 для этого запроса. Тогда идеальный порядок:  \n",
    "**3, 3, 3, 2, 2, 2, 1, 0**  \n",
    "Без D7 и D8 идеальный порядок:  \n",
    "**3, 3, 2, 2, 1, 0**  \n",
    "DCG этого идеального порядка, или IDCG (Ideal DCG) , вычисляется до ранга 6:  \n",
    "![image](IDCG6.png)  \n",
    "Итак, nDCG для этого запроса имеет следующий вид:  \n",
    "![image](nDCG6.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ограничения:  \n",
    "1. Нормализованная метрика DCG не наказывает за плохие документы в результате. Например, если запрос возвращает два результата с оценками 1,1,1 и 1,1,1,0 соответственно, оба будут считаться одинаково хорошими, даже если последний содержит плохой документ. Для рейтинговых оценок « Отлично», « Удовлетворительно» , «Плохо» можно использовать числовые баллы 1,0, -1 вместо 2,1,0 . Это приведет к снижению оценки, если будут возвращены плохие результаты, при этом точность результатов будет важнее отзыва. Обратите внимание, что этот подход может привести к общей отрицательной оценке, которая сместит нижнюю границу оценки с 0 на отрицательное значение.  \n",
    "2. Нормализованный DCG не наказывает за пропущенные документы в результате. Например, если запрос возвращает два результата с оценками 1,1,1 и 1,1,1,1,1 соответственно, оба будут считаться одинаково хорошими, если предположить, что идеальный DCG вычислен для ранга 3 для первого и ранга 5 для последний. Один из способов учесть это ограничение - установить фиксированный размер набора для набора результатов и использовать минимальные баллы для отсутствующих документов. В предыдущем примере мы использовали бы оценки 1,1,1,0,0 и 1,1,1,1,1 и процитировали бы nDCG как nDCG @ 5.  \n",
    "3. Нормализованный DCG может не подходить для измерения производительности запросов, которые часто могут давать несколько одинаково хороших результатов. Это особенно верно, когда эта метрика ограничивается только несколькими первыми результатами, как это делается на практике. Например, для таких запросов, как «рестораны» nDCG @ 1 будет учитывать только первый результат, и, следовательно, если один набор результатов содержит только 1 ресторан из соседнего района, а другой - 5, оба будут иметь одинаковую оценку, даже если последнее является более полным. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо логарифма можно использовать сигмоиду (это гладкая монотонная возрастающая нелинейная функция, имеющая форму буквы «S», которая часто применяется для «сглаживания» значений некоторой величины). Эта функция, названная в честь s-образной формы её графика, просто выдаёт число, равное обратному отношения шансов. Таким образом, область значений у нас сокращается до [0, 1]. Мы можем взять любой Х на вход и проследить ход работы модели вплоть до предсказанного значения У. Это значение и будет вероятностью отношения Х к тому или иному классу. Сегодня сигмоида является одной из самых частых активационных функций в нейросетях. \n",
    "\n",
    "Ещё можно использовать гиперболический тангенс. Гиперболический тангенс очень похож на сигмоиду. И действительно, это скорректированная сигмоидная функция. Поэтому такая функция имеет те же характеристики, что и у сигмоиды. Её природа нелинейна, она хорошо подходит для комбинации слоёв, а диапазон значений функции -(-1, 1). Поэтому нет смысла беспокоиться, что активационная функция перегрузится от больших значений. Однако стоит отметить, что градиент тангенциальной функции больше, чем у сигмоиды (производная круче). Решение о том, выбрать ли сигмоиду или тангенс, зависит от ваших требований к амплитуде градиента. Также как и сигмоиде, гиперболическому тангенсу свойственная проблема исчезновения градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Какие еще метрики (Вы можете вспомнить уже пройденные Вами или посмотреть в интернете) могут использоваться для рекомендательных систем (приведите примеры метрики и чем являются интеракции, чтобы она могла быть использована).**  \n",
    "\n",
    "**Метрики класса Prediction Accuracy — оценивают точность предсказываемого рейтинга:**  \n",
    "MAE (Mean Absolute Error) - Среднее абсолютное отклонение.  \n",
    "MSE (Mean Squared Error) - Среднеквадратичная ошибка.  \n",
    "RMSE (Root Mean Squared Error) - Корень из среднеквадратичной ошибки.  \n",
    "\n",
    "**Метрики класса Decision Support:**    \n",
    "Precision - доля рекомендаций, понравившихся пользователю.  \n",
    "Recall - доля интересных пользователю товаров, которая показана.  \n",
    "F1-Measure - Среднее гармоническое метрик Precision и Recall. Полезно, когда заранее невозможно сказать, какая из метрик важнее.  \n",
    "ROC AUC - Насколько высока концентрация интересных товаров в начале списка рекомендаций.  \n",
    "Precision@N - Метрика Precision, посчитанная на Top-N записях.  \n",
    "Recall@N - Метрика Recall, посчитанная на Top-N записях.  \n",
    "AverageP - Среднее значение Precision на всем списке рекомендаций.  \n",
    "\n",
    "**Метрики класса Rank Accuracy:**  \n",
    "Mean Reciprocal Rank - На какой позиции списка рекомендаций пользователь находит первую полезную.  \n",
    "Spearman Correlation - Корреляция (Спирмена) реального и прогнозируемого рангов рекомендаций.  \n",
    "nDCG - Информативность выдачи с учетом ранжирования рекомендаций.  \n",
    "Fraction of Concordance Pairs - Насколько высока концентрация интересных товаров в начале списка рекомендаций.  \n",
    "\n",
    "В качестве метрик также можно использовать ранговые коэффициенты корреляции Кенделла, Мэтьюса, Крамера и другие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) boughted = [1, 3, 5, 7, 9, 11]  \n",
    "recommended = [2, 5, 7, 4, 11, 9, 8, 10, 12, 3]  \n",
    "Посчитайте на этих данных pr@8, rec@8, AP@8, NDCG@8, RR@8, ERR@8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boughted = [1, 3, 5, 7, 9, 11]\n",
    "recommended = [2, 5, 7, 4, 11, 9, 8, 10, 12, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pr@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended_list, bought_list, k=5):\n",
    "    \n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)\n",
    "    \n",
    "    bought_list = bought_list  # Тут нет [:k] !!\n",
    "    recommended_list = recommended_list[:k]\n",
    "    \n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "    # print(flags)\n",
    "     \n",
    "    precision = flags.sum() / len(recommended_list)\n",
    "     \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_at_k(recommended, boughted, k=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rec@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended_list, bought_list, k=5):\n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)[:k]\n",
    "    \n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "    \n",
    "    recall = flags.sum() / len(bought_list)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(recommended, boughted, k=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_k(recommended_list, bought_list, k=5):\n",
    "    \n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)\n",
    "    \n",
    "    flags = np.isin(recommended_list, bought_list)\n",
    "    \n",
    "    if sum(flags) == 0:\n",
    "        return 0\n",
    "    \n",
    "    sum_ = 0\n",
    "    for i in range(1, k+1): \n",
    "        if flags[i] == True:\n",
    "            p_k = precision_at_k(recommended_list, bought_list, k=i)\n",
    "            sum_ += p_k\n",
    "            \n",
    "    result = sum_ / sum(flags)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_k(recommended, boughted, k=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG_at_k(recommended_list, bought_list, k):\n",
    "    recommended_list = recommended_list[:k]\n",
    "    if recommended_list[0] in bought_list:\n",
    "        dcg = 1\n",
    "    else: dcg = 0\n",
    "    for i in range(1, len(recommended_list)):\n",
    "        if recommended_list[i] in bought_list:\n",
    "            dcg += 1/np.log(i+1)\n",
    "       \n",
    "    idcg = 1\n",
    "    for i in range(1, k):\n",
    "        idcg += 1/np.log(i+1)  \n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5653142737255068"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCG_at_k(recommended, boughted, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RR@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_at_k(recommended_list, bought_list, k):\n",
    "    recommended_list = recommended_list[:k]\n",
    "    ranks = 0\n",
    "    for item_rec in recommended_list:\n",
    "        for i, item_bought in enumerate(bought_list):\n",
    "            if item_rec == item_bought:\n",
    "                ranks += 1 / (i+1)\n",
    "    return ranks / len(recommended_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11875"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reciprocal_rank_at_k(recommended, boughted, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERR@8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_reciprocal_rank_at_k(recommended_list, k):\n",
    "    if k <= 0:\n",
    "        return -1\n",
    "    \n",
    "    if len(recommended_list) < k:\n",
    "        k = len(recommended_list)\n",
    "    \n",
    "    recommended_list = recommended_list[:k]\n",
    "    \n",
    "    grade = max(recommended_list)\n",
    "    prob = [0]\n",
    "    prob.extend((2**i-1)/2**grade for i in range(1, grade+1))\n",
    "    \n",
    "    return sum(1/i*prob[recommended_list[i-1]]*np.prod([1-prob[recommended_list[j-1]] for j in range(1, i)]) for i in range(1, k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2141286747780282"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_reciprocal_rank_at_k(recommended, 8)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP3RP3q/8ZgEDVF3p/rximj",
   "collapsed_sections": [],
   "name": "hw_03.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
