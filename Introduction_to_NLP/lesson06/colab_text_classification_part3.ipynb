{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# Загрузка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baYFZMW_bJHh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWVWjyIkffau"
   },
   "source": [
    "Тексты трех переводов выполнили:\n",
    "\n",
    " - [Вильям Купер](https://en.wikipedia.org/wiki/William_Cowper) — [текст](https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt)\n",
    "\n",
    " - [Эрл Эдвард](https://en.wikipedia.org/wiki/Edward_Smith-Stanley,_14th_Earl_of_Derby) — [текст](https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt)\n",
    "\n",
    "- [Сэмюель Батлер](https://en.wikipedia.org/wiki/Samuel_Butler_%28novelist%29) — [текст](https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt)\n",
    "\n",
    "Текстовые файлы использованные в этом руководстве были подвергнуты некоторым типичным задачам предварительной обработки, в основном удаление материала - шапка и футер документа, нумерация строк, заголовки глав. Скачайте эти файлы локально."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "executionInfo": {
     "elapsed": 6411,
     "status": "ok",
     "timestamp": 1607187166777,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "4YlKQthEYlFw",
    "outputId": "635029c2-4b81-4daa-aa20-ec8d7e7a1bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt\n",
      "819200/815980 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n",
      "811008/809730 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n",
      "811008/807992 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/root/.keras/datasets'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
    "FILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
    "\n",
    "for name in FILE_NAMES:\n",
    "  text_dir = tf.keras.utils.get_file(name, origin=DIRECTORY_URL+name)\n",
    "  \n",
    "parent_dir = os.path.dirname(text_dir)\n",
    "\n",
    "parent_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3sDy6nuXoNp"
   },
   "source": [
    "## Загрузите текст в датасеты\n",
    "\n",
    "Переберите файлы, загружая каждый в свой датасет.\n",
    "\n",
    "Каждый пример нужно пометить индивидуально, так что используйте `tf.data.Dataset.map` чтобы применить функцию расставляющую метки каждому элементу. Она переберет каждую запись в датасете возвращая пару (`example, label`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0BjCOpOh7Ch"
   },
   "outputs": [],
   "source": [
    "def labeler(example, index):\n",
    "  return example, tf.cast(index, tf.int64)  \n",
    "\n",
    "labeled_data_sets = []\n",
    "\n",
    "for i, file_name in enumerate(FILE_NAMES):\n",
    "  lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))\n",
    "  labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
    "  labeled_data_sets.append(labeled_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8PHK5J_cXE5"
   },
   "source": [
    "Объедините эти размеченные наборы данных в один и перемешайте его.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jAeYkTIi9-2"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "TAKE_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qd544E-Sh63L"
   },
   "outputs": [],
   "source": [
    "all_labeled_data = labeled_data_sets[0]\n",
    "for labeled_dataset in labeled_data_sets[1:]:\n",
    "  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
    "  \n",
    "all_labeled_data = all_labeled_data.shuffle(\n",
    "    BUFFER_SIZE, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4JEHrJXeG5k"
   },
   "source": [
    "Вы можете использовать `tf.data.Dataset.take` и `print`, чтобы посмотреть как выглядят пары `(example, label)`. Свойство `numpy` показывает каждое значение тензора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2006,
     "status": "ok",
     "timestamp": 1607187206451,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "gywKlN0xh6u5",
    "outputId": "173ffbc4-7b41-4c57-c391-d0e8b4d092ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'More than a woman or a puny child:'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'The Trojans, Hector and \\xc3\\x86neas rush'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'\"Hector, thou son of Priam, leave me not'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Some say hereafter, Menelaus bore'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"To avenge her slaughter'd brothers on his head.\">, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "for ex in all_labeled_data.take(5):\n",
    "  print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rrpU2_sfDh0"
   },
   "source": [
    "## Закодируйте текстовые строки числами\n",
    "\n",
    "Модели машинного обучения работают с числами, не словами, так что строковые значения необходимо конвертировать в списки с числами. Чтобы сделать это поставьте в соответствие каждому слову свое число.\n",
    "\n",
    "### Создайте словарь\n",
    "\n",
    "Сперва создайте словарь токенизировав текст в коллекцию отдельных отличающихся слов. Есть несколько способов сделать это и в TensorFlow и в Python. В этом учебнике:\n",
    "\n",
    "1. Переберите `numpy` значения всех примеров.\n",
    "2. Используйте `tfds.features.text.Tokenizer` чтобы разбить их на токены.\n",
    "3. Соберите эти токены в множество Python чтобы избавиться от дубликатов\n",
    "4. Получите размер словаря для последующего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wRWyRx5Zhcx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6868,
     "status": "ok",
     "timestamp": 1607187227980,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "YkHtbGnDh6mg",
    "outputId": "f3153ba2-4963-42cc-82cc-46f6650ea8fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17178"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tfds.deprecated.text.Tokenizer()\n",
    "# tf.keras.preprocessing.text.Tokenizer()\n",
    "tf.keras.preprocessing.sequence.\n",
    "vocabulary_set = set()\n",
    "for text_tensor, _ in all_labeled_data:\n",
    "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "  vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkxJIVAth6j0"
   },
   "outputs": [],
   "source": [
    "encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6S5Qyabi-vo"
   },
   "source": [
    "Вы можете посмотреть одну строку чтобы увидеть как выглядит результат работы кодировщика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1625,
     "status": "ok",
     "timestamp": 1607187238290,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "jgxPZaxUuTbk",
    "outputId": "0e57dc0d-416a-429b-f57f-647159679a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'More than a woman or a puny child:'\n"
     ]
    }
   ],
   "source": [
    "example_text = next(iter(all_labeled_data))[0].numpy()\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1607187238829,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "XoVpKR3qj5yb",
    "outputId": "7ac0eb2a-e70b-4a13-abef-6fa3dd13da43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4385, 13505, 5499, 3662, 3117, 5499, 5549, 14418]\n"
     ]
    }
   ],
   "source": [
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9qHM0v8k_Mg"
   },
   "source": [
    "Теперь запустите кодировщик на датасете обернув его в `tf.py_function` и передав в метод `map` датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcIQ7LOTh6eT"
   },
   "outputs": [],
   "source": [
    "def encode(text_tensor, label):\n",
    "  encoded_text = encoder.encode(text_tensor.numpy())\n",
    "  return encoded_text, label\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "  # py_func doesn't set the shape of the returned tensors.\n",
    "  encoded_text, label = tf.py_function(encode, \n",
    "                                       inp=[text, label], \n",
    "                                       Tout=(tf.int64, tf.int64))\n",
    "\n",
    "  # `tf.data.Datasets` work best if all components have a shape set\n",
    "  #  so set the shapes manually: \n",
    "  encoded_text.set_shape([None])\n",
    "  label.set_shape([])\n",
    "\n",
    "  return encoded_text, label\n",
    "\n",
    "\n",
    "all_encoded_data = all_labeled_data.map(encode_map_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YZToSXSm0qr"
   },
   "source": [
    "## Разбейте датасет на тестовую и обучающую выборки\n",
    "\n",
    "Используйте `tf.data.Dataset.take` и `tf.data.Dataset.skip` чтобы создать небольшой тестовый и большой обучающий датасеты.\n",
    "\n",
    "Перед передачей в модель датасет должны быть разбиты на пакеты. Обычно количество записей в пакете и их размерность должно быть одинаковые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-rmbijQh6bf"
   },
   "outputs": [],
   "source": [
    "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_data = train_data.padded_batch(BATCH_SIZE)\n",
    "\n",
    "test_data = all_encoded_data.take(TAKE_SIZE)\n",
    "test_data = test_data.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xdz7SVwmqi1l"
   },
   "source": [
    "Сейчас, `test_data` и `train_data` являются не коллекциями пар (`example, label`), а коллекциями пакетов. Каждый пакет это пара вида (*много примеров*, *много меток*) представленная в виде массивов.\n",
    "\n",
    "Чтобы проиллюстрировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2004,
     "status": "ok",
     "timestamp": 1607187247230,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "kMslWfuwoqpB",
    "outputId": "fbb0f577-802d-4413-e078-b735dfbc2aba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(17,), dtype=int64, numpy=\n",
       " array([ 4385, 13505,  5499,  3662,  3117,  5499,  5549, 14418,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text, sample_labels = next(iter(test_data))\n",
    "\n",
    "sample_text[0], sample_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI4I6_Sa0vWu"
   },
   "source": [
    "Так как мы ввели новую кодировку токенов (нуль использовался для заполнения), размер словаря увеличился на единицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlD1Lli91vuc"
   },
   "outputs": [],
   "source": [
    "vocab_size += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8SUhGFNsmRi"
   },
   "source": [
    "## Постройте модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJgI1pow2YR9"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR6-ctbY638P"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Embedding(vocab_size, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6rnq6DN_WUs"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.GlobalAveragePooling1D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTEaNSnLCsv5"
   },
   "outputs": [],
   "source": [
    "# Один или более плотных слоев.\n",
    "# Отредактируйте список в строке `for` чтобы поэкспериментировать с размером слоев.\n",
    "for units in [64, 64]:\n",
    "  model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "\n",
    "# Выходной слой. Первый аргумент - число меток.\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLHPU8q5DLi_"
   },
   "source": [
    "Наконец скомпилируйте модель. Для softmax категоризационной модели используйте `sparse_categorical_crossentropy` в виде функции потерь. Вы можете попробовать другие оптимизаторы, но `adam` очень часто используемая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1607187335380,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "KqqLYK71rrxi",
    "outputId": "9ea3e4e6-0f45-4e27-919c-cfa97b64f021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          1099456   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,107,971\n",
      "Trainable params: 1,107,971\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkTBUVO4h6Y5"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM-HLo5NDhql"
   },
   "source": [
    "## Обучите модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76782,
     "status": "ok",
     "timestamp": 1607187430631,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "aLtO33tNh6V8",
    "outputId": "3e768fbc-dcab-47aa-8e6d-14236c473fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "697/697 [==============================] - 11s 16ms/step - loss: 0.5495 - accuracy: 0.7392 - val_loss: 0.4135 - val_accuracy: 0.8146\n",
      "Epoch 2/3\n",
      "697/697 [==============================] - 11s 16ms/step - loss: 0.3182 - accuracy: 0.8615 - val_loss: 0.3790 - val_accuracy: 0.8302\n",
      "Epoch 3/3\n",
      "697/697 [==============================] - 12s 17ms/step - loss: 0.2423 - accuracy: 0.8952 - val_loss: 0.3919 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f175e0497f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=3, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTPCYf_Jh6TH",
    "outputId": "ec59cb79-8c6a-4e74-8dc3-061e92c462f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 23ms/step - loss: 0.3701 - accuracy: 0.8384\n",
      "\n",
      "Eval loss: 0.370, Eval accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_acc = model.evaluate(test_data)\n",
    "\n",
    "print('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYKrznEDsfW8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
