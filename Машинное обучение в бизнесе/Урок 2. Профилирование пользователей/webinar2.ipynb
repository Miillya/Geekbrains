{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 2. Профилирование пользователей. Сегментация аудитории: unsupervised learning (clustering, LDA/ARTM), supervised (multi/binary classification)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План занятия:\n",
    "\n",
    "1. задача сегментации аудитории по интересам - для чего\n",
    "2. тематическое моделирование - получаем эмбединги текстов\n",
    "3. решаем downstream-задачу (профилирование аудитории новостного портала)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассматривать мы все будем в контексте решения конкретной прикладной задачи - задачи оттока"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача сегментации (неформальное определение)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем пользователей на группы, чем-то отличающиеся друг от друга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же более формально, то:\n",
    "\n",
    "Сегментация клиентской базы — это способ повышения эффективности работы с пользователями путем их распределения по отдельным группам, или сегментам, в соответствии с их запросами и/или потребностями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегментация может быть очень разной:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. когда совершил первую покупку (сколько прошло с момента регистрации до момента покупки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](payments1.png \"Payments2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. по психотипам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](psycho.png \"Psycho\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. по платежам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](payments.png \"Payments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. По эффективности взаимодействия (uplift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](uplift.png \"Uplift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. по интересам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](interests.png \"Interests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И еще 100500 вариантов сегментирования, которое может быть полезно. \n",
    "\n",
    "Для чего полезно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. понимание аудитории, способность описать основные группы пользователей и их интересы\n",
    "2. выявление сегментов с максимальной монетизацией\n",
    "3. выбор маркетинговой стратегии\n",
    "4. налаживание эффективного взаимодействия с пользователями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример из жизни (новостной портал)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что мы - компания-агрегатор новостей (новостной портал).\n",
    "\n",
    "У нас есть:\n",
    "\n",
    "1. читатели\n",
    "2. новости\n",
    "\n",
    "Для каждого пользователя мы можем за какой-то период (например, 1 день) достать из базы данных список прочитанных им новостей.\n",
    "\n",
    "Для каждой новости мы можем вытащить текст и метаинформацию.\n",
    "\n",
    "### Задача #1: нужно построить модель прогнозирования оттока - это наша downstream-задача. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужны:\n",
    "\n",
    "1. векторное представление пользователя\n",
    "2. сегменты, описывающие интересы пользователя\n",
    "\n",
    "p.s. в контексте нашей задачи - это одно и то же"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С чего начнем?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С векторного представления и сегментов новостей!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть два очевидных варианта как это сделать:\n",
    "\n",
    "1. многоклассовая классификация\n",
    "2. кластеризация документов с последующей попыткой их (кластера) интерпретировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. для классификации нам нужно сначала разметить новости - привлечение ручного труда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Терминология:\n",
    "\n",
    "1. документ - коллекция слов \n",
    "2. тема - набор токенов (слов), совместно часто встречающихся в документах\n",
    "\n",
    "Более формально:\n",
    "\n",
    "1. тема - условное распределение на множестве терминов, p(w|t)\n",
    "2. тематический профиль документа - условное распределение тем p(t|d)\n",
    "\n",
    "Вопрос: что же нам дано (в терминах условной вероятности)?\n",
    "\n",
    "Ответ: условное распределение слов в документах - p(w|d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прекрасное объяснение от Воронцова - http://www.machinelearning.ru/wiki/images/d/d5/Voron17survey-artm.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическая модель позволяет нам получить p(w|t), p(t|d) по известным p(w|d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](tm1.png \"TM1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переходим к практике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:72,5% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:72,5% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('precision', 3)\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСергейnИвановnизбран председателем советаnПБК ЦСКАn. Как сообщаетnпресс-службаnармейцев, такое решение было единогласно принято на первом заседании совета клуба. Основной функцией этого органа будет обсуждение текущего состояния, планирование и утвержден...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был приостановлен судьей из-за взрыва пиротехнических снарядов, передает корреспондент «Газеты.Ru». Болельщики выбросили на поле петарды. Судья увел команды с поля в подтрибунное помещение. Динамовцы ушли, а торпедовцы остались у кромки поля. Сообщается, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокомментировал игру своей команды в матче чемпионата КХЛ против «Атланта»n(4:3)n.nn«Мы провели плохой матч в Нижнем Новгороде против «Торпедо» и настраивались, что с первых же минут включимся в работу, — сказал Заборский. — У нас получилось забросить быстрый...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  \\\n",
       "0       6   \n",
       "1    4896   \n",
       "2    4897   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                         title  \n",
       "0  Заместитель председателяnправительства РФnСергейnИвановnизбран председателем советаnПБК ЦСКАn. Как сообщаетnпресс-службаnармейцев, такое решение было единогласно принято на первом заседании совета клуба. Основной функцией этого органа будет обсуждение текущего состояния, планирование и утвержден...  \n",
       "1  Матч 1/16 финала Кубка России по футболу был приостановлен судьей из-за взрыва пиротехнических снарядов, передает корреспондент «Газеты.Ru». Болельщики выбросили на поле петарды. Судья увел команды с поля в подтрибунное помещение. Динамовцы ушли, а торпедовцы остались у кромки поля. Сообщается, ...  \n",
       "2  Форвард «Авангарда» Томаш Заборский прокомментировал игру своей команды в матче чемпионата КХЛ против «Атланта»n(4:3)n.nn«Мы провели плохой матч в Нижнем Новгороде против «Торпедо» и настраивались, что с первых же минут включимся в работу, — сказал Заборский. — У нас получилось забросить быстрый...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"articles.csv\")\n",
    "print(news.shape)\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26997</th>\n",
       "      <td>513443</td>\n",
       "      <td>Американские ученые уточнили возраст расположенного в американском штате Аризона Гранд-Каньона, сообщается в их статье, опубликованной в научном журналеnNature Geosciencen.nТак, ученые полагают, что возраст каньона составляет примерно 5–6 млн лет, в то время как прежде было принято считать, что ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>513444</td>\n",
       "      <td>За последние 50 лет тропический углеродный цикл стал в два раза чувствительнее к изменениям температуры, сообщается вnстатьеn, опубликованной в научном журнале Nature.nВ частности, американским ученым удалось выяснить, что повышение температуры в джунглях на 1° C приводит к тому, что в атмосферу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>513445</td>\n",
       "      <td>У живших примерно 7 тыс. лет назад на территории современной Испании охотников-собирателей были голубые глаза и смуглая кожа, выяснили испанские ученые, статья которыхnопубликованаnв научном журнале Nature.nВосстановить облик La Braña, а именно так исследователи «окрестили» жившего в период мезо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id  \\\n",
       "26997  513443   \n",
       "26998  513444   \n",
       "26999  513445   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                             title  \n",
       "26997  Американские ученые уточнили возраст расположенного в американском штате Аризона Гранд-Каньона, сообщается в их статье, опубликованной в научном журналеnNature Geosciencen.nТак, ученые полагают, что возраст каньона составляет примерно 5–6 млн лет, в то время как прежде было принято считать, что ...  \n",
       "26998  За последние 50 лет тропический углеродный цикл стал в два раза чувствительнее к изменениям температуры, сообщается вnстатьеn, опубликованной в научном журнале Nature.nВ частности, американским ученым удалось выяснить, что повышение температуры в джунглях на 1° C приводит к тому, что в атмосферу...  \n",
       "26999  У живших примерно 7 тыс. лет назад на территории современной Испании охотников-собирателей были голубые глаза и смуглая кожа, выяснили испанские ученые, статья которыхnопубликованаnв научном журнале Nature.nВосстановить облик La Braña, а именно так исследователи «окрестили» жившего в период мезо...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим пользователей и списки последних прочитанных новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"users_articles.csv\")\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, нам нужно получить векторные представления пользователей на основе прочитанным ими новостей и самих новостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Получаем векторные представления новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install razdel\n",
    "# !pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка текстов\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "from razdel import tokenize # https://github.com/natasha/razdel\n",
    "\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "\n",
    "stopword_ru = stopwords.words('russian')\n",
    "len(stopword_ru)\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|nn|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    \n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Busi\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Possible nested set at position 39\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем очистку текста. Будет долго...\n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Запускаем лемматизацию текста. Будет очень долго...\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь в 3 строчки обучим нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сформируем список наших текстов, разбив еще и на пробелы\n",
    "texts = [t for t in news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое common_dictionary и как он выглядит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'взаимодействие'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_dictionary[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все просто - это словарь наших слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary)#, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "# Save model to disk.\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучили модель. Теперь 2 вопроса:\n",
    "\n",
    "1. как выглядят наши темы\n",
    "2. как получить для документа вектор значений (вероятности принадлежности каждой теме)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'свой', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'провести', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'работа', 'сказать', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'мочь', 'играть', 'ещё', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'это', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 0.14490137),\n",
       " (3, 0.057951253),\n",
       " (4, 0.07384094),\n",
       " (8, 0.07324749),\n",
       " (10, 0.03355841),\n",
       " (14, 0.5527861),\n",
       " (16, 0.047334775)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "other_texts = [t for t in news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: год это который рубль мочь рост также\n",
      "topic_1: мальчик озеро соцсеть жир взорваться фото норвежский\n",
      "topic_2: физика медицина кровь рекомендовать больной уточнять лёд\n",
      "topic_3: женщина человек мужчина рейс задержать это исследование\n",
      "topic_4: температура экипаж северный место вода высота южный\n",
      "topic_5: год который свой это земля человек жизнь\n",
      "topic_6: который военный год это власть санкция россия\n",
      "topic_7: ребёнок цена тыс год млн гражданин семья\n",
      "topic_8: погибнуть поверхность рак годовой фронт восточный отель\n",
      "topic_9: это который сша человек россия мочь всё\n",
      "topic_10: ракета египет дождь су экскурсия снежный воздух\n",
      "topic_11: китай участок восток активность китайский доклад торговый\n",
      "topic_12: ставка планета кольцо мэй билет сахар банк\n",
      "topic_13: украина украинский гражданин киев народный сон украинец\n",
      "topic_14: конкурс дыра обращение стать увидеть сайт знаменитый\n",
      "topic_15: год который это исследование город находиться человек\n",
      "topic_16: прогнозировать транспорт санктпетербург квартира железнодорожный предполагать дикий\n",
      "topic_17: компания банк рынок научный работа директор который\n",
      "topic_18: это миссия который человек всё свой планета\n",
      "topic_19: вицепремьер предприниматель снять ск определение собственность ухо\n",
      "topic_20: турция турецкий зарегистрировать операция донбасс опрос украинский\n",
      "topic_21: это год россия который российский новый мочь\n",
      "topic_22: газ запуск солнце иран бомба полоса километр\n",
      "topic_23: двигатель завод мозг млрд кожа туризм потребность\n",
      "topic_24: исследование россиянин снизиться сократиться подчёркивать остров японский\n"
     ]
    }
   ],
   "source": [
    "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "#Below Code Prints Only Words \n",
    "for topic,words in topics_words:\n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень неплохо - большинство тем вполне можно описать о чем они"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте напишем функцию, которая будет нам возвращать векторное представление новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = news['title'].iloc[0]\n",
    "\n",
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01297</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07459</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.88266</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01102</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.31169</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.35124</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04290</td>\n",
       "      <td>0.27315</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.14490</td>\n",
       "      <td>0.05785</td>\n",
       "      <td>0.07385</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07326</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03356</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.55287</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04734</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.25772</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.40318</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03034</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10550</td>\n",
       "      <td>0.19355</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.47748</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04286</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.18722</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.26898</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  topic_0  topic_1  topic_2  topic_3  topic_4  topic_5  topic_6  \\\n",
       "0       6  0.00000  0.00000  0.01297  0.00000  0.00000  0.00000  0.00000   \n",
       "1    4896  0.00000  0.00000  0.31169  0.00000  0.00000  0.35124  0.00000   \n",
       "2    4897  0.00000  0.00000  0.14490  0.05785  0.07385  0.00000  0.00000   \n",
       "3    4898  0.25772  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000   \n",
       "4    4899  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.47748   \n",
       "\n",
       "   topic_7  topic_8  topic_9  topic_10  topic_11  topic_12  topic_13  \\\n",
       "0  0.00000  0.00000  0.00000   0.00000   0.00000   0.00000   0.00000   \n",
       "1  0.00000  0.00000  0.00000   0.00000   0.00000   0.00000   0.00000   \n",
       "2  0.00000  0.07326  0.00000   0.03356   0.00000   0.00000   0.00000   \n",
       "3  0.00000  0.00000  0.00000   0.00000   0.00000   0.00000   0.00000   \n",
       "4  0.00000  0.00000  0.00000   0.00000   0.04286   0.00000   0.00000   \n",
       "\n",
       "   topic_14  topic_15  topic_16  topic_17  topic_18  topic_19  topic_20  \\\n",
       "0   0.07459   0.00000   0.00000   0.88266   0.00000   0.01102   0.00000   \n",
       "1   0.04290   0.27315   0.00000   0.00000   0.00000   0.00000   0.00000   \n",
       "2   0.55287   0.00000   0.04734   0.00000   0.00000   0.00000   0.00000   \n",
       "3   0.40318   0.00000   0.00000   0.00000   0.03034   0.00000   0.00000   \n",
       "4   0.18722   0.00000   0.26898   0.00000   0.00000   0.00000   0.00000   \n",
       "\n",
       "   topic_21  topic_22  topic_23  topic_24  \n",
       "0   0.00000   0.00000   0.00000   0.01113  \n",
       "1   0.00000   0.00000   0.00000   0.00000  \n",
       "2   0.00000   0.00000   0.00000   0.00000  \n",
       "3   0.10550   0.19355   0.00000   0.00000  \n",
       "4   0.00000   0.00000   0.00000   0.00000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "topic_matrix.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прекрасно, мы получили вектора наших новостей! И даже умеем интерпретировать получившиеся темы.\n",
    "\n",
    "Можно двигаться далее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Следующий шаг - векторные представления пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13648446, 0.        , 0.        , 0.12210447, 0.        ,\n",
       "       0.        , 0.14885312, 0.02298531, 0.        , 0.11994407,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.23329769,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1238676 , 0.08198699, 0.        , 0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict[293622]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_articles_list = users['articles'].iloc[33]\n",
    "\n",
    "def get_user_embedding(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "#     Среднее значение\n",
    "    user_vector = np.mean(user_vector, 0)\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15941853, 0.        , 0.00191423, 0.05107567, 0.00341535,\n",
       "       0.07878571, 0.16406548, 0.01478833, 0.        , 0.06631303,\n",
       "       0.        , 0.01318078, 0.        , 0.        , 0.00447703,\n",
       "       0.09603349, 0.00501727, 0.01244238, 0.        , 0.        ,\n",
       "       0.        , 0.31401623, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_embedding(user_articles_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересовался новостями с топиками topic_3, topic_14 (что-то про политику и государство)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[323329, 321961, 324743, 323186, 324632, 474690]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['articles'].iloc[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'глава российский мид сергей лавров опровергнуть появиться сми информация якобы готовиться обмен декларация россия сша сотрудничество сфера сообщать риа новость читать сообщение разговаривать автор сообщение знать откуда автор источник какихлибо основание подобный род репортаж знать откуда информация появиться сказать журналист итог встреча госсекретарь сша джон керри позиция свой изложить декларация напринимать достаточно рамка обсе рамка совет россия нато высокий уровень продекларировать всё обеспечивать неделимость безопасность никто обеспечивать свой безопасность счёт безопасность продолжить министр слово лавров москва считать система нато создавать проблема наш безопасность поэтому декларация недостаточно мочь договариваться совместный система россия предлагать ещё начинать год президент путин посещать сша нужно вести речь очередной декларация гарантия который проверять объективный военнотехнический критерий гарантия ненаправленность система против российский ядерный потенциал подчеркнуть глава мид вторник газета коммерсантъ ссылаться дипломатический источник написать барак обама владимир путин выйти тупик обменяться политический декларация пообещать использовать свой потенциал друг против друг'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(news[news['doc_id']==323186]['title'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь получим эмбединги для всех пользователей и проверим их качество на конкретной downstream-задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.06426</td>\n",
       "      <td>0.00566</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09356</td>\n",
       "      <td>0.01014</td>\n",
       "      <td>0.03583</td>\n",
       "      <td>0.03740</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.00232</td>\n",
       "      <td>0.07770</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01261</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04364</td>\n",
       "      <td>0.11127</td>\n",
       "      <td>0.18325</td>\n",
       "      <td>0.00825</td>\n",
       "      <td>0.03980</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.13589</td>\n",
       "      <td>0.02120</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.07718</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04823</td>\n",
       "      <td>0.00717</td>\n",
       "      <td>0.05731</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.03292</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.14668</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.00999</td>\n",
       "      <td>0.13249</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>0.04782</td>\n",
       "      <td>0.01987</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.25278</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.10283</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>0.02611</td>\n",
       "      <td>0.02830</td>\n",
       "      <td>0.04360</td>\n",
       "      <td>0.15155</td>\n",
       "      <td>0.01335</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>0.07743</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00769</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.32044</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03990</td>\n",
       "      <td>0.01204</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11077</td>\n",
       "      <td>0.01373</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  topic_0  topic_1  topic_2  topic_3  topic_4  topic_5  topic_6  \\\n",
       "0  u105138  0.06426  0.00566  0.00000  0.09356  0.01014  0.03583  0.03740   \n",
       "1  u108690  0.07718  0.00242  0.00000  0.04823  0.00717  0.05731  0.09740   \n",
       "2  u108339  0.10283  0.00000  0.00272  0.02611  0.02830  0.04360  0.15155   \n",
       "\n",
       "   topic_7  topic_8  topic_9  topic_10  topic_11  topic_12  topic_13  \\\n",
       "0  0.09616  0.00232  0.07770   0.00000   0.01261   0.00000   0.04364   \n",
       "1  0.03292  0.00000  0.14668   0.00000   0.00485   0.00000   0.03321   \n",
       "2  0.01335  0.01353  0.07743   0.00000   0.00769   0.00000   0.00245   \n",
       "\n",
       "   topic_14  topic_15  topic_16  topic_17  topic_18  topic_19  topic_20  \\\n",
       "0   0.11127   0.18325   0.00825   0.03980   0.00000   0.00000   0.00000   \n",
       "1   0.00999   0.13249   0.00206   0.04782   0.01987   0.00331   0.00174   \n",
       "2   0.00908   0.32044   0.00000   0.03990   0.01204   0.00539   0.00000   \n",
       "\n",
       "   topic_21  topic_22  topic_23  topic_24  \n",
       "0   0.13589   0.02120   0.00000   0.00000  \n",
       "1   0.25278   0.00541   0.00000   0.00353  \n",
       "2   0.11077   0.01373   0.00191   0.00000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "user_embeddings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет готов - можно попробовать обучить модель. Загрузим нашу разметку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u107120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u102277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u102444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  churn\n",
       "0  u107120      0\n",
       "1  u102277      0\n",
       "2  u102444      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"users_churn.csv\")\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.06426</td>\n",
       "      <td>0.00566</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09356</td>\n",
       "      <td>0.01014</td>\n",
       "      <td>0.03583</td>\n",
       "      <td>0.03740</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.00232</td>\n",
       "      <td>0.07770</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01261</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04364</td>\n",
       "      <td>0.11127</td>\n",
       "      <td>0.18325</td>\n",
       "      <td>0.00825</td>\n",
       "      <td>0.03980</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.13589</td>\n",
       "      <td>0.02120</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.07718</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.04823</td>\n",
       "      <td>0.00717</td>\n",
       "      <td>0.05731</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.03292</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.14668</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.00999</td>\n",
       "      <td>0.13249</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>0.04782</td>\n",
       "      <td>0.01987</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.25278</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.10283</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>0.02611</td>\n",
       "      <td>0.02830</td>\n",
       "      <td>0.04360</td>\n",
       "      <td>0.15155</td>\n",
       "      <td>0.01335</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>0.07743</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00769</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.32044</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03990</td>\n",
       "      <td>0.01204</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.11077</td>\n",
       "      <td>0.01373</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  topic_0  topic_1  topic_2  topic_3  topic_4  topic_5  topic_6  \\\n",
       "0  u105138  0.06426  0.00566  0.00000  0.09356  0.01014  0.03583  0.03740   \n",
       "1  u108690  0.07718  0.00242  0.00000  0.04823  0.00717  0.05731  0.09740   \n",
       "2  u108339  0.10283  0.00000  0.00272  0.02611  0.02830  0.04360  0.15155   \n",
       "\n",
       "   topic_7  topic_8  topic_9  topic_10  topic_11  topic_12  topic_13  \\\n",
       "0  0.09616  0.00232  0.07770   0.00000   0.01261   0.00000   0.04364   \n",
       "1  0.03292  0.00000  0.14668   0.00000   0.00485   0.00000   0.03321   \n",
       "2  0.01335  0.01353  0.07743   0.00000   0.00769   0.00000   0.00245   \n",
       "\n",
       "   topic_14  topic_15  topic_16  topic_17  topic_18  topic_19  topic_20  \\\n",
       "0   0.11127   0.18325   0.00825   0.03980   0.00000   0.00000   0.00000   \n",
       "1   0.00999   0.13249   0.00206   0.04782   0.01987   0.00331   0.00174   \n",
       "2   0.00908   0.32044   0.00000   0.03990   0.01204   0.00539   0.00000   \n",
       "\n",
       "   topic_21  topic_22  topic_23  topic_24  churn  \n",
       "0   0.13589   0.02120   0.00000   0.00000      0  \n",
       "1   0.25278   0.00541   0.00000   0.00353      1  \n",
       "2   0.11077   0.01373   0.00191   0.00000      1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.merge(user_embeddings, target, 'left')\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "#обучим наш пайплайн\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22236558, 0.04999086, 0.34480705, 0.1508781 , 0.11939552,\n",
       "       0.08281255, 0.06302002, 0.03404715, 0.11699578, 0.1943919 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds = logreg.predict_proba(X_test)[:, 1]\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассчитаем Precision, Recall, F_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.237499, F-Score=0.623, Precision=0.532, Recall=0.751\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1593  162]\n",
      " [  62  183]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#мы уже нашли ранее \"оптимальный\" порог, когда максимизировали f_score\n",
    "font = {'size' : 15}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, preds>thresholds[ix])\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Non-Churn', 'churn'],\n",
    "                      title='Confusion matrix')\n",
    "plt.savefig(\"conf_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317099831385546"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rating = [fscore[ix], precision[ix], recall[ix], roc_auc_score(y_test, preds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом мы видим, что получившиеся векторные представления содержат какой-то сигнал и позволяют решать нашу прикладную задачу. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Самостоятельно разобраться с тем, что такое tfidf (документация https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html и еще - https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
    "3. Повторить п.2, но используя уже не медиану, а max\n",
    "4. (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес.\n",
    "5. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
    "6. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. http://www.machinelearning.ru/wiki/images/d/d5/Voron17survey-artm.pdf\n",
    "2. https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Медиана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12004006, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01406113, 0.08438075, 0.        , 0.        , 0.01659563,\n",
       "       0.        , 0.00663645, 0.        , 0.        , 0.        ,\n",
       "       0.0977858 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.36029348, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_user_embedding(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.median(user_vector, 0)\n",
    "    return user_vector\n",
    "\n",
    "\n",
    "get_user_embedding(user_articles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "\n",
    "X = pd.merge(user_embeddings, target, 'left')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)\n",
    "\n",
    "#обучим наш пайплайн\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "preds = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rating = [fscore[ix], precision[ix], recall[ix], roc_auc_score(y_test, preds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Максимальное значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40033883, 0.        , 0.0114854 , 0.28377751, 0.02049213,\n",
       "       0.34468317, 0.47768536, 0.06553932, 0.        , 0.22955711,\n",
       "       0.        , 0.03737004, 0.        , 0.        , 0.0268622 ,\n",
       "       0.21723954, 0.03010365, 0.05581421, 0.        , 0.        ,\n",
       "       0.        , 0.58007115, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_user_embedding(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.max(user_vector, 0)\n",
    "    return user_vector\n",
    "\n",
    "\n",
    "get_user_embedding(user_articles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "\n",
    "X = pd.merge(user_embeddings, target, 'left')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)\n",
    "\n",
    "#обучим наш пайплайн\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "preds = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rating = [fscore[ix], precision[ix], recall[ix], roc_auc_score(y_test, preds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимальноеное значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.05065276, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_user_embedding(user_articles_list):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = np.min(user_vector, 0)\n",
    "    return user_vector\n",
    "\n",
    "\n",
    "get_user_embedding(user_articles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x), 1)])\n",
    "user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]\n",
    "\n",
    "X = pd.merge(user_embeddings, target, 'left')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[['topic_{}'.format(i) for i in range(25)]], \n",
    "                                                    X['churn'], random_state=0)\n",
    "\n",
    "#обучим наш пайплайн\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "preds = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating = [fscore[ix], precision[ix], recall[ix], roc_auc_score(y_test, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.62267</td>\n",
       "      <td>0.53179</td>\n",
       "      <td>0.75102</td>\n",
       "      <td>0.93171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.72651</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.71020</td>\n",
       "      <td>0.96139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.75149</td>\n",
       "      <td>0.73256</td>\n",
       "      <td>0.77143</td>\n",
       "      <td>0.96811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.52174</td>\n",
       "      <td>0.40449</td>\n",
       "      <td>0.73469</td>\n",
       "      <td>0.89284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1_score  precision  recall  roc_auc_score\n",
       "mean     0.62267    0.53179 0.75102        0.93171\n",
       "median   0.72651    0.74359 0.71020        0.96139\n",
       "max      0.75149    0.73256 0.77143        0.96811\n",
       "min      0.52174    0.40449 0.73469        0.89284"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'mean': mean_rating, 'median': median_rating, 'max': max_rating, 'min': min_rating}).T\n",
    "results.columns=['f1_score', 'precision', 'recall', 'roc_auc_score']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение значениями медианы и максимума улучшили точность модели, а между precision и recall допустимый интервал. При использовании минимальных значений происходит обратное, наблюдается существенное снижение всех показателей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"users_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u101138</td>\n",
       "      <td>[5933, 6186, 5055, 6977, 5206, 488389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u108248</td>\n",
       "      <td>[707, 1144, 2532, 2928, 3133, 324592]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]\n",
       "3  u101138          [5933, 6186, 5055, 6977, 5206, 488389]\n",
       "4  u108248           [707, 1144, 2532, 2928, 3133, 324592]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['articles'] = users['articles'].apply(lambda x: \"\".join([i.strip() for i in x.replace(\"[\",\"\").replace(\"]\",\"\")]), \n",
    "                                            1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'293672,293328,293001,293622,293126,1852'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['articles'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(users['articles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8.88871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>7.90788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>8.04141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>8.88871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002</td>\n",
       "      <td>8.88871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14776</th>\n",
       "      <td>995</td>\n",
       "      <td>8.37788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14777</th>\n",
       "      <td>996</td>\n",
       "      <td>8.19556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14778</th>\n",
       "      <td>997</td>\n",
       "      <td>8.60103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14779</th>\n",
       "      <td>998</td>\n",
       "      <td>9.29417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14780</th>\n",
       "      <td>999</td>\n",
       "      <td>8.60103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14781 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id     idf\n",
       "0             10 8.88871\n",
       "1            100 7.90788\n",
       "2           1000 8.04141\n",
       "3           1001 8.88871\n",
       "4           1002 8.88871\n",
       "...          ...     ...\n",
       "14776        995 8.37788\n",
       "14777        996 8.19556\n",
       "14778        997 8.60103\n",
       "14779        998 9.29417\n",
       "14780        999 8.60103\n",
       "\n",
       "[14781 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'article_id': tfidf.get_feature_names(),\n",
    "             'idf': tfidf.idf_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'article_id': tfidf.get_feature_names(),\n",
    "             'idf': tfidf.idf_}).to_csv(\"articles_idf.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
