{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"hw_02.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"taken-surge"},"source":["## Фреймворк PyTorch для разработки искусственных нейронных сетей   \n","### Урок 2. CNN and LSTM for human action recognition"],"id":"taken-surge"},{"cell_type":"markdown","metadata":{"id":"processed-parallel"},"source":["1.\tПриложен ноутбук, в котором реализованы функции для генерации из большого датасета меньшая его копия. Вам нужно перенести функции из этого ноутбука в класс датасет и сделать следующее:   \n","a.\tСгенерировать меньший датасет из 8-10 классов движения;  \n","b.\tОбучить уже существующую модель (предварительно проанализировав какие параметры модели нужно изменить);   \n","c.\tИзменить модель: посмотреть зависимость от количества LSTM модулей в нашей модели;  \n","d.\tСгенерировать другой датасет с меньшим количеством “кадров” в серии и сравнить улучшилось или ухудшилось качество предсказания. Провести несколько таких итераций, дать свою оценку уменьшению и увеличению кадров, назвать оптимальное, на ваш взгляд, их количество. Желательно сделать так, чтобы длина последовательности передавалась как атрибут класса. "],"id":"processed-parallel"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"smaller-bernard","executionInfo":{"status":"ok","timestamp":1614765139847,"user_tz":-180,"elapsed":875,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"61ea80d2-bbe4-4e47-dc46-feca0ffc1fcc"},"source":["from IPython.core.display import display, HTML, Image\n","display(HTML(\"<style>.container { width:77% !important; }</style>\"))"],"id":"smaller-bernard","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["<style>.container { width:77% !important; }</style>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"swedish-property","executionInfo":{"status":"ok","timestamp":1614765140199,"user_tz":-180,"elapsed":955,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["import os\n","import time\n","import math\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"id":"swedish-property","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"worthy-robertson","executionInfo":{"status":"ok","timestamp":1614765140201,"user_tz":-180,"elapsed":610,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["plt.rcParams.update({'font.size': 14})\n","pd.set_option('precision', 3)\n","pd.set_option('max_columns', 100)\n","pd.set_option('display.float_format', lambda x: '%.5f' % x)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('max_colwidth', 300)"],"id":"worthy-robertson","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"unable-default","executionInfo":{"status":"ok","timestamp":1614765140669,"user_tz":-180,"elapsed":536,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["import torch\n","import torchvision\n","from torch import nn \n","from torch import optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Dataset"],"id":"unable-default","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"white-helena","executionInfo":{"status":"ok","timestamp":1614765141010,"user_tz":-180,"elapsed":442,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"e0307812-f16d-4d76-e0ed-e287c5afc86a"},"source":["use_cuda = torch.cuda.is_available()\n","# device = torch.device(\"cpu\")\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)"],"id":"white-helena","execution_count":12,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0rj2Wn2R11I","executionInfo":{"status":"ok","timestamp":1614765173122,"user_tz":-180,"elapsed":20188,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"77996ddb-4782-443d-81a1-d52e1b364d8e"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"id":"z0rj2Wn2R11I","execution_count":15,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xtbhWIabeeiz","executionInfo":{"status":"ok","timestamp":1614766600167,"user_tz":-180,"elapsed":484,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["dst_path = \"/content/drive/MyDrive/Colab Notebooks/my_projects/nturgbd_skeletons_s001_to_s017.zip\""],"id":"xtbhWIabeeiz","execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"dV3BtIHyefTL","executionInfo":{"status":"ok","timestamp":1614768216742,"user_tz":-180,"elapsed":587,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["# from zipfile import ZipFile\r\n","# zipfile = ZipFile(dst_path)\r\n","# zipfile.extractall()"],"id":"dV3BtIHyefTL","execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTuBD_o9kVVB","executionInfo":{"status":"ok","timestamp":1614766932040,"user_tz":-180,"elapsed":1007,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["data_path = \"/content/nturgb+d_skeletons/\"\n","broken_files_path = \"/content/drive/MyDrive/Colab Notebooks/my_projects/NTURGB-D-master/Matlab/NTU_RGBD_samples_with_missing_skeletons.txt\""],"id":"VTuBD_o9kVVB","execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyric-singapore"},"source":["#### a.\tСгенерировать меньший датасет из 8-10 классов движения;   "],"id":"lyric-singapore"},{"cell_type":"code","metadata":{"id":"sustainable-correspondence","executionInfo":{"status":"ok","timestamp":1614772563425,"user_tz":-180,"elapsed":576,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["training_subjects = list(range(0, 28)) # количество людей выполняющих действия\n","training_classes = [8, 10, 22, 23, 27, 21, 5, 17, 1, 32] # классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\n","training_cameras = [1, 2, 3] \n","\n","max_body_true = 1\n","max_body_kinect = 1\n","\n","# num_joint = 25\n","# max_frame = 300 # Длина отрезка которую мы вычленяем из большого датасета"],"id":"sustainable-correspondence","execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"occupational-promotion","executionInfo":{"status":"ok","timestamp":1614772565257,"user_tz":-180,"elapsed":872,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["class Generate_Dataset(Dataset):\n","    def __init__(self, data_path, broken_files_path=None, training_classes=None,\n","                 num_joint = 25, max_frame = 300, transform=None):\n","               \n","        def read_data(data_path, broken_files_path):\n","            labels = []\n","            files = []\n","            action_classes = {}\n","            counter = 0\n","            files_counter = {}\n","            \n","            with open(broken_files_path, 'r') as f:\n","                broken_files = f.read().split(\"\\n\")\n","\n","            raw_files = os.listdir(data_path)\n","            num_frames = 0\n","\n","            for filename in raw_files:\n","                if filename not in broken_files:\n","                    action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\n","                    subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\n","                    camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\n","                    if action_class in training_classes and camera_id in training_cameras:  # and subject_id in training_subjects:\n","                        if action_class in action_classes:\n","                            if files_counter[action_class] < 120:\n","                                files.append([filename,action_classes[action_class]])\n","                                files_counter[action_class] = files_counter[action_class] + 1\n","                        else:\n","                            action_classes.update({action_class : counter})\n","                            files_counter.update({action_class : 1})\n","                            counter+=1\n","                            files.append([filename,action_classes[action_class]])\n","#                             labels.append([action_class])\n","            print(\"action classes: \", action_classes)\n","            print(\"action files: \", files_counter)\n","\n","            return files, action_classes\n","        \n","        # Функция фильтр для того, что бы найти только координаты x,y,z(т.к. в датасете\n","        # хранится на порядок больше информации, нежели только координаты x,y,z)\n","        # (Остальные данные нам и не нужны, т.к. у нас нет ик-камер)\n","        def read_skeleton_filter(file):\n","            with open(file, 'r') as f:\n","                skeleton_sequence = {}\n","                skeleton_sequence['numFrame'] = int(f.readline())\n","                skeleton_sequence['frameInfo'] = []\n","                for t in range(skeleton_sequence['numFrame']):\n","                    frame_info = {}\n","                    frame_info['numBody'] = int(f.readline())\n","                    frame_info['bodyInfo'] = []\n","\n","                    for m in range(frame_info['numBody']):\n","                        body_info = {}\n","                        body_info_key = [\n","                            'bodyID', 'clipedEdges', 'handLeftConfidence',\n","                            'handLeftState', 'handRightConfidence', 'handRightState',\n","                            'isResticted', 'leanX', 'leanY', 'trackingState'\n","                        ]\n","                        body_info = {\n","                            k: float(v)\n","                            for k, v in zip(body_info_key, f.readline().split())\n","                        }\n","                        body_info['numJoint'] = int(f.readline())\n","                        body_info['jointInfo'] = []\n","                        for v in range(body_info['numJoint']):\n","                            joint_info_key = [\n","                                'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n","                                'orientationW', 'orientationX', 'orientationY',\n","                                'orientationZ', 'trackingState'\n","                            ]\n","                            joint_info = {\n","                                k: float(v)\n","                                for k, v in zip(joint_info_key, f.readline().split())\n","                            }\n","                            body_info['jointInfo'].append(joint_info)\n","                        frame_info['bodyInfo'].append(body_info)\n","                    skeleton_sequence['frameInfo'].append(frame_info)\n","\n","            return skeleton_sequence\n","\n","        def read_xyz(file, max_body=1, num_joint=25):\n","            seq_info = read_skeleton_filter(file)\n","            data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\n","            for n, f in enumerate(seq_info['frameInfo']):\n","                for m, b in enumerate(f['bodyInfo']):\n","                    for j, v in enumerate(b['jointInfo']):\n","                        if m < max_body and j < num_joint:\n","                            data[m, n, j, :] = [v['x'], v['y'], v['z']]\n","\n","                        else:\n","                            pass\n","\n","            return data\n","        \n","        \n","        def create_coords_blocks(test_file, chonk_len = 45):   \n","            frame_counter = 0\n","            new_labels = []\n","            new_frames = []\n","            blocks = []\n","\n","            test_frames = read_xyz(data_path + test_file[0])[0]\n","            label = test_file[1]\n","            slice_len = chonk_len * int(len(test_frames)/chonk_len)\n","\n","\n","            for index in range(len(test_frames[:slice_len])):\n","                frame_counter += 1\n","                new_frames.append(test_frames[index].flatten())\n","                if frame_counter == chonk_len:\n","                    frame_counter = 0\n","                    blocks.append(np.array(new_frames))\n","                    new_labels = new_labels + [label]\n","                    new_frames = []\n","\n","\n","            return blocks, new_labels\n","        \n","        \n","        ##### список файлов с лейблами на каждый файл \n","        working_files_with_labels, action_classes = read_data(data_path, broken_files_path)\n","        \n","        data = []\n","        labels = []\n","        ##########################################################################\n","        numbers = {x: 0 for x in range(len(action_classes))}  #####\n","        ##################################################################\n","        for file in working_files_with_labels:\n","            frames_blocks, label = create_coords_blocks(file)\n","            if label != [] and numbers[label[0]] <= 150:\n","                numbers[label[0]] = numbers[label[0]] + len(label)\n","                data = data + frames_blocks\n","                labels = labels + label\n","        data_np = np.asarray(data)\n","        labels_np = np.asarray(labels)\n","\n","        data_sq = data_np.reshape(len(data_np), -1)\n","        data = pd.DataFrame(data_sq)\n","        labels = pd.DataFrame(labels_np)\n","        data['labels'] = labels\n","        \n","\n","        self.data = data\n","        self.labels = data['labels'].astype('float32')\n","        self.transform = transform\n","        \n","           \n","    def __len__(self):\n","         return len(self.data)\n","        \n","        \n","    def __getitem__(self, idx):\n","        item = np.asarray(self.data.iloc[idx,:-1]).reshape(45,75)\n","        label = self.labels[idx]\n","        if self.transform != None:\n","            item = transform(item)\n","        return (item, label) "],"id":"occupational-promotion","execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"signed-madrid","executionInfo":{"status":"ok","timestamp":1614772580936,"user_tz":-180,"elapsed":14928,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"e2e685f3-dd79-4382-f099-44efc8328a66"},"source":["dataset = Generate_Dataset(data_path=data_path, broken_files_path=broken_files_path, \n","                           training_classes=training_classes,num_joint = 25, \n","                           max_frame = 300, transform=None)"],"id":"signed-madrid","execution_count":68,"outputs":[{"output_type":"stream","text":["action classes:  {23: 0, 1: 1, 17: 2, 5: 3, 32: 4, 21: 5, 10: 6, 22: 7, 8: 8, 27: 9}\n","action files:  {23: 120, 1: 120, 17: 120, 5: 120, 32: 120, 21: 120, 10: 120, 22: 120, 8: 120, 27: 120}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"distinguished-float"},"source":["#### b. Обучить уже существующую модель (предварительно проанализировав какие параметры модели нужно изменить);"],"id":"distinguished-float"},{"cell_type":"code","metadata":{"id":"internal-obligation","executionInfo":{"status":"ok","timestamp":1614772581740,"user_tz":-180,"elapsed":789,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.75*len(dataset)),\n","                                                                      len(dataset) - int(0.75*len(dataset))])\n","train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=True)"],"id":"internal-obligation","execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"temporal-adapter","executionInfo":{"status":"ok","timestamp":1614772581741,"user_tz":-180,"elapsed":782,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["class LSTM_net(nn.Module):\n","    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.output_dim = output_dim\n","        self.lstm = torch.nn.LSTM(input_dim, hidden_dim,layer_num,batch_first=True)\n","        self.dr = torch.nn.Dropout2d(0.1)\n","        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n","        \n","        \n","    def forward(self,inputs):\n","        x = inputs\n","        lstm_out,(hn,cn) = self.lstm(x)\n","        out = self.fc(lstm_out[:,-1,:])\n","        return out"],"id":"temporal-adapter","execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"ongoing-documentation","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614772581742,"user_tz":-180,"elapsed":776,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"576563e5-f27c-43ee-a667-b6eaa2c8cfd6"},"source":["n_hidden = 128\n","n_joints = 25*3\n","n_categories = len(training_subjects)\n","n_layer = 2\n","rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n","rnn.to(device)"],"id":"ongoing-documentation","execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM_net(\n","  (lstm): LSTM(75, 128, num_layers=2, batch_first=True)\n","  (dr): Dropout2d(p=0.1, inplace=False)\n","  (fc): Linear(in_features=128, out_features=28, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"annual-panama","executionInfo":{"status":"ok","timestamp":1614772581743,"user_tz":-180,"elapsed":767,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["def categoryFromOutput(output):\n","    top_n, top_i = output.topk(1)\n","    category_i = top_i[0].item()\n","#     print(output.topk(5))\n","    return training_subjects[category_i], category_i\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)"],"id":"annual-panama","execution_count":72,"outputs":[]},{"cell_type":"code","metadata":{"id":"fleet-ozone","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614773613801,"user_tz":-180,"elapsed":1032817,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"9450ed99-0315-4036-a5b1-8b4ae277594d"},"source":["criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.0007\n","optimizer = optim.SGD(rnn.parameters(), lr=learning_rate, momentum=0.9)\n","\n","all_losses = []\n","start = time.time()\n","counter = 0\n","for epoch in range(600):  \n","    current_loss = 0\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        \n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        optimizer.zero_grad()\n","    \n","        output = rnn(inputs.float())\n","        labels = labels.type(torch.LongTensor).to(device)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step() \n","\n","\n","        current_loss += loss.item()\n","        category = training_subjects[int(labels[0])]\n","\n","        if counter % 500 == 0:\n","            guess, guess_i = categoryFromOutput(output)\n","            correct = '✓' if guess == category else '✗ (%s)' % category\n","            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n","\n","        \n","        counter = counter + 1\n","    if counter % 100 == 0:\n","        all_losses.append(current_loss / 25)\n","        current_loss = 0"],"id":"fleet-ozone","execution_count":73,"outputs":[{"output_type":"stream","text":["epoch : 0 iter : 0 (0m 0s) 3.3488  / 12 ✗ (9)\n","epoch : 7 iter : 59 (0m 13s) 2.4529  / 2 ✗ (6)\n","epoch : 15 iter : 55 (0m 27s) 2.3436  / 4 ✗ (5)\n","epoch : 23 iter : 51 (0m 41s) 2.2969  / 1 ✗ (7)\n","epoch : 31 iter : 47 (0m 54s) 2.3287  / 4 ✗ (6)\n","epoch : 39 iter : 43 (1m 8s) 2.2838  / 4 ✗ (9)\n","epoch : 47 iter : 39 (1m 22s) 2.1977  / 2 ✗ (7)\n","epoch : 55 iter : 35 (1m 35s) 2.1461  / 8 ✓\n","epoch : 63 iter : 31 (1m 49s) 2.0513  / 7 ✓\n","epoch : 71 iter : 27 (2m 3s) 1.9635  / 2 ✗ (3)\n","epoch : 79 iter : 23 (2m 16s) 1.8958  / 8 ✗ (1)\n","epoch : 87 iter : 19 (2m 30s) 1.6430  / 2 ✓\n","epoch : 95 iter : 15 (2m 44s) 1.5512  / 4 ✗ (1)\n","epoch : 103 iter : 11 (2m 58s) 1.6860  / 9 ✗ (3)\n","epoch : 111 iter : 7 (3m 11s) 1.9012  / 2 ✗ (6)\n","epoch : 119 iter : 3 (3m 25s) 1.9208  / 4 ✓\n","epoch : 126 iter : 62 (3m 39s) 1.5984  / 2 ✓\n","epoch : 134 iter : 58 (3m 52s) 1.7174  / 0 ✓\n","epoch : 142 iter : 54 (4m 6s) 2.0724  / 6 ✗ (4)\n","epoch : 150 iter : 50 (4m 20s) 1.6661  / 1 ✗ (4)\n","epoch : 158 iter : 46 (4m 33s) 2.0766  / 5 ✗ (1)\n","epoch : 166 iter : 42 (4m 47s) 1.7408  / 2 ✓\n","epoch : 174 iter : 38 (5m 1s) 1.7727  / 5 ✓\n","epoch : 182 iter : 34 (5m 14s) 1.5491  / 2 ✗ (8)\n","epoch : 190 iter : 30 (5m 28s) 1.2684  / 6 ✗ (4)\n","epoch : 198 iter : 26 (5m 42s) 1.6109  / 1 ✗ (4)\n","epoch : 206 iter : 22 (5m 55s) 1.1045  / 8 ✗ (2)\n","epoch : 214 iter : 18 (6m 9s) 1.3768  / 1 ✗ (6)\n","epoch : 222 iter : 14 (6m 23s) 1.4251  / 6 ✗ (0)\n","epoch : 230 iter : 10 (6m 36s) 1.5342  / 6 ✗ (4)\n","epoch : 238 iter : 6 (6m 50s) 1.0869  / 1 ✗ (5)\n","epoch : 246 iter : 2 (7m 3s) 1.2779  / 9 ✓\n","epoch : 253 iter : 61 (7m 17s) 0.8926  / 9 ✓\n","epoch : 261 iter : 57 (7m 31s) 1.6166  / 4 ✓\n","epoch : 269 iter : 53 (7m 44s) 0.9473  / 1 ✓\n","epoch : 277 iter : 49 (7m 58s) 1.1906  / 0 ✗ (5)\n","epoch : 285 iter : 45 (8m 12s) 0.8862  / 4 ✓\n","epoch : 293 iter : 41 (8m 25s) 0.9647  / 0 ✗ (5)\n","epoch : 301 iter : 37 (8m 39s) 0.8672  / 0 ✗ (5)\n","epoch : 309 iter : 33 (8m 53s) 0.7049  / 9 ✗ (3)\n","epoch : 317 iter : 29 (9m 6s) 0.9076  / 5 ✓\n","epoch : 325 iter : 25 (9m 20s) 1.2579  / 7 ✓\n","epoch : 333 iter : 21 (9m 34s) 0.9734  / 3 ✓\n","epoch : 341 iter : 17 (9m 47s) 0.7682  / 4 ✓\n","epoch : 349 iter : 13 (10m 1s) 1.1050  / 2 ✗ (7)\n","epoch : 357 iter : 9 (10m 14s) 0.7119  / 4 ✓\n","epoch : 365 iter : 5 (10m 28s) 0.6879  / 0 ✗ (4)\n","epoch : 373 iter : 1 (10m 42s) 0.8253  / 6 ✓\n","epoch : 380 iter : 60 (10m 55s) 0.3823  / 4 ✓\n","epoch : 388 iter : 56 (11m 9s) 0.8020  / 5 ✓\n","epoch : 396 iter : 52 (11m 23s) 0.4632  / 1 ✗ (4)\n","epoch : 404 iter : 48 (11m 36s) 0.7566  / 7 ✓\n","epoch : 412 iter : 44 (11m 50s) 0.2812  / 0 ✓\n","epoch : 420 iter : 40 (12m 3s) 0.6071  / 1 ✗ (0)\n","epoch : 428 iter : 36 (12m 17s) 1.0425  / 2 ✗ (8)\n","epoch : 436 iter : 32 (12m 31s) 0.4566  / 1 ✓\n","epoch : 444 iter : 28 (12m 44s) 0.6308  / 1 ✗ (4)\n","epoch : 452 iter : 24 (12m 58s) 0.7640  / 2 ✗ (0)\n","epoch : 460 iter : 20 (13m 12s) 0.1844  / 9 ✓\n","epoch : 468 iter : 16 (13m 25s) 0.3112  / 2 ✗ (4)\n","epoch : 476 iter : 12 (13m 39s) 0.4823  / 2 ✓\n","epoch : 484 iter : 8 (13m 52s) 0.6091  / 9 ✓\n","epoch : 492 iter : 4 (14m 6s) 0.2036  / 2 ✓\n","epoch : 500 iter : 0 (14m 20s) 1.1926  / 2 ✓\n","epoch : 507 iter : 59 (14m 33s) 0.2868  / 1 ✓\n","epoch : 515 iter : 55 (14m 47s) 0.2403  / 2 ✓\n","epoch : 523 iter : 51 (15m 0s) 0.1546  / 0 ✓\n","epoch : 531 iter : 47 (15m 14s) 0.9146  / 4 ✓\n","epoch : 539 iter : 43 (15m 28s) 0.2989  / 5 ✓\n","epoch : 547 iter : 39 (15m 41s) 0.3182  / 8 ✓\n","epoch : 555 iter : 35 (15m 55s) 0.1941  / 9 ✓\n","epoch : 563 iter : 31 (16m 9s) 0.1351  / 3 ✓\n","epoch : 571 iter : 27 (16m 22s) 0.0619  / 6 ✓\n","epoch : 579 iter : 23 (16m 36s) 0.4899  / 8 ✓\n","epoch : 587 iter : 19 (16m 50s) 0.2631  / 0 ✓\n","epoch : 595 iter : 15 (17m 3s) 0.1025  / 4 ✓\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"explicit-surname","executionInfo":{"status":"ok","timestamp":1614773613804,"user_tz":-180,"elapsed":1028069,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["plt.plot(list(range(0, len(all_losses))), all_losses)\n","plt.show()"],"id":"explicit-surname","execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"deadly-helen","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614773614785,"user_tz":-180,"elapsed":1027671,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"c39c094b-6775-4394-d629-b9dc2d4d16ca"},"source":["total = 0\n","right = 0\n","counter = 0\n","\n","rnn.eval()\n","with torch.no_grad():\n","    for i, data in enumerate(test_loader, 0):\n","        counter = counter + 1\n","        inputs, labels = data[0].to(device), data[1].to(device)  \n","        output = rnn(inputs.float())\n","        guess, guess_i = categoryFromOutput(output)\n","        category = training_subjects[int(labels[0])]\n","        \n","        if guess == category:\n","            right = right + 1\n","\n","\n","print('Accuracy of the network:  ',  (100 * right / counter))"],"id":"deadly-helen","execution_count":75,"outputs":[{"output_type":"stream","text":["Accuracy of the network:   54.166666666666664\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"critical-relevance"},"source":["#### c. Изменить модель: посмотреть зависимость от количества LSTM модулей в нашей модели;"],"id":"critical-relevance"},{"cell_type":"code","metadata":{"id":"ruled-essex","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614773615967,"user_tz":-180,"elapsed":1159,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"aee6e996-5577-4a2e-e3b2-71f818661314"},"source":["n_hidden = 128*4\n","n_joints = 25*3\n","n_categories = len(training_subjects)\n","n_layer = 2\n","rnn = LSTM_net(n_joints, n_hidden, n_categories, n_layer)\n","rnn.to(device)"],"id":"ruled-essex","execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM_net(\n","  (lstm): LSTM(75, 512, num_layers=2, batch_first=True)\n","  (dr): Dropout2d(p=0.1, inplace=False)\n","  (fc): Linear(in_features=512, out_features=28, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"accomplished-template","executionInfo":{"status":"ok","timestamp":1614773615968,"user_tz":-180,"elapsed":1147,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["class LSTM_net(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, layer_num):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.output_dim = output_dim\n","        self.lstm = torch.nn.LSTM(input_dim, hidden_dim, layer_num, batch_first=True)\n","        self.dr = torch.nn.Dropout2d(0.1)\n","        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n","        \n","        \n","    def forward(self,inputs):\n","        x = inputs\n","        lstm_out,(hn,cn) = self.lstm(x)\n","        out = self.fc(lstm_out[:,-1,:])\n","        return out"],"id":"accomplished-template","execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"certain-cowboy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614775037134,"user_tz":-180,"elapsed":1422305,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"ef3bb747-9889-444f-8934-c16205ede0b6"},"source":["criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.0007\n","optimizer = optim.SGD(rnn.parameters(), lr=learning_rate, momentum=0.9)\n","\n","all_losses = []\n","start = time.time()\n","counter = 0\n","for epoch in range(600):  \n","    current_loss = 0\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        \n","        inputs, labels = data[0].to(device), data[1].to(device)\n","        optimizer.zero_grad()\n","    \n","        output = rnn(inputs.float())\n","        labels = labels.type(torch.LongTensor).to(device)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step() \n","\n","\n","        current_loss += loss.item()\n","        category = training_subjects[int(labels[0])]\n","\n","        if counter % 500 == 0:\n","            guess, guess_i = categoryFromOutput(output)\n","            correct = '✓' if guess == category else '✗ (%s)' % category\n","            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n","\n","        \n","        counter = counter + 1\n","    if counter % 100 == 0:\n","        all_losses.append(current_loss / 25)\n","        current_loss = 0"],"id":"certain-cowboy","execution_count":78,"outputs":[{"output_type":"stream","text":["epoch : 0 iter : 0 (0m 0s) 3.3485  / 27 ✗ (3)\n","epoch : 7 iter : 59 (0m 18s) 2.3252  / 4 ✗ (1)\n","epoch : 15 iter : 55 (0m 37s) 2.3149  / 4 ✗ (1)\n","epoch : 23 iter : 51 (0m 56s) 2.3503  / 4 ✗ (9)\n","epoch : 31 iter : 47 (1m 15s) 2.2324  / 4 ✗ (7)\n","epoch : 39 iter : 43 (1m 34s) 2.3096  / 2 ✗ (5)\n","epoch : 47 iter : 39 (1m 52s) 2.0123  / 1 ✗ (3)\n","epoch : 55 iter : 35 (2m 11s) 2.0790  / 7 ✗ (1)\n","epoch : 63 iter : 31 (2m 30s) 1.7078  / 1 ✗ (5)\n","epoch : 71 iter : 27 (2m 49s) 1.8507  / 8 ✗ (2)\n","epoch : 79 iter : 23 (3m 7s) 1.7720  / 2 ✓\n","epoch : 87 iter : 19 (3m 26s) 1.5761  / 6 ✓\n","epoch : 95 iter : 15 (3m 45s) 2.1973  / 4 ✗ (3)\n","epoch : 103 iter : 11 (4m 4s) 1.7577  / 2 ✗ (0)\n","epoch : 111 iter : 7 (4m 22s) 1.6777  / 1 ✓\n","epoch : 119 iter : 3 (4m 41s) 1.6725  / 1 ✗ (3)\n","epoch : 126 iter : 62 (5m 0s) 1.3975  / 1 ✗ (6)\n","epoch : 134 iter : 58 (5m 19s) 1.4410  / 7 ✓\n","epoch : 142 iter : 54 (5m 37s) 1.1981  / 3 ✓\n","epoch : 150 iter : 50 (5m 56s) 1.5572  / 3 ✗ (1)\n","epoch : 158 iter : 46 (6m 15s) 1.9897  / 6 ✗ (7)\n","epoch : 166 iter : 42 (6m 34s) 1.3216  / 1 ✓\n","epoch : 174 iter : 38 (6m 52s) 1.4817  / 5 ✗ (6)\n","epoch : 182 iter : 34 (7m 11s) 1.1990  / 2 ✓\n","epoch : 190 iter : 30 (7m 30s) 1.2176  / 8 ✓\n","epoch : 198 iter : 26 (7m 49s) 1.3695  / 1 ✓\n","epoch : 206 iter : 22 (8m 7s) 1.0069  / 3 ✓\n","epoch : 214 iter : 18 (8m 26s) 0.7139  / 2 ✓\n","epoch : 222 iter : 14 (8m 45s) 1.1557  / 6 ✗ (7)\n","epoch : 230 iter : 10 (9m 4s) 1.2121  / 3 ✓\n","epoch : 238 iter : 6 (9m 23s) 0.8080  / 6 ✗ (1)\n","epoch : 246 iter : 2 (9m 42s) 0.7534  / 1 ✓\n","epoch : 253 iter : 61 (10m 1s) 0.8727  / 2 ✗ (8)\n","epoch : 261 iter : 57 (10m 20s) 0.7359  / 1 ✓\n","epoch : 269 iter : 53 (10m 39s) 1.2566  / 8 ✓\n","epoch : 277 iter : 49 (10m 57s) 0.6033  / 7 ✓\n","epoch : 285 iter : 45 (11m 16s) 1.4361  / 8 ✓\n","epoch : 293 iter : 41 (11m 35s) 0.7122  / 0 ✓\n","epoch : 301 iter : 37 (11m 54s) 0.5077  / 5 ✓\n","epoch : 309 iter : 33 (12m 13s) 0.4543  / 0 ✓\n","epoch : 317 iter : 29 (12m 32s) 0.6264  / 3 ✓\n","epoch : 325 iter : 25 (12m 50s) 0.3768  / 3 ✓\n","epoch : 333 iter : 21 (13m 9s) 0.1493  / 2 ✓\n","epoch : 341 iter : 17 (13m 28s) 0.2455  / 2 ✓\n","epoch : 349 iter : 13 (13m 47s) 0.0609  / 7 ✓\n","epoch : 357 iter : 9 (14m 6s) 0.1280  / 1 ✓\n","epoch : 365 iter : 5 (14m 25s) 0.2901  / 6 ✓\n","epoch : 373 iter : 1 (14m 44s) 0.0407  / 0 ✓\n","epoch : 380 iter : 60 (15m 2s) 0.0366  / 1 ✓\n","epoch : 388 iter : 56 (15m 21s) 0.0132  / 2 ✓\n","epoch : 396 iter : 52 (15m 40s) 0.0706  / 7 ✓\n","epoch : 404 iter : 48 (15m 59s) 0.0082  / 2 ✓\n","epoch : 412 iter : 44 (16m 17s) 0.0089  / 4 ✓\n","epoch : 420 iter : 40 (16m 36s) 0.0094  / 5 ✓\n","epoch : 428 iter : 36 (16m 55s) 0.0054  / 6 ✓\n","epoch : 436 iter : 32 (17m 14s) 0.0029  / 1 ✓\n","epoch : 444 iter : 28 (17m 32s) 0.0025  / 9 ✓\n","epoch : 452 iter : 24 (17m 51s) 0.0044  / 9 ✓\n","epoch : 460 iter : 20 (18m 10s) 0.0052  / 3 ✓\n","epoch : 468 iter : 16 (18m 28s) 0.0451  / 8 ✓\n","epoch : 476 iter : 12 (18m 47s) 0.0034  / 8 ✓\n","epoch : 484 iter : 8 (19m 6s) 0.0988  / 5 ✓\n","epoch : 492 iter : 4 (19m 25s) 0.0017  / 1 ✓\n","epoch : 500 iter : 0 (19m 43s) 0.0010  / 4 ✓\n","epoch : 507 iter : 59 (20m 2s) 0.0014  / 8 ✓\n","epoch : 515 iter : 55 (20m 21s) 0.0017  / 3 ✓\n","epoch : 523 iter : 51 (20m 40s) 0.0020  / 2 ✓\n","epoch : 531 iter : 47 (20m 59s) 0.1187  / 5 ✗ (8)\n","epoch : 539 iter : 43 (21m 18s) 0.0018  / 3 ✓\n","epoch : 547 iter : 39 (21m 36s) 0.0014  / 6 ✓\n","epoch : 555 iter : 35 (21m 56s) 0.1063  / 6 ✓\n","epoch : 563 iter : 31 (22m 15s) 0.0010  / 2 ✓\n","epoch : 571 iter : 27 (22m 33s) 0.0021  / 8 ✓\n","epoch : 579 iter : 23 (22m 52s) 0.0017  / 6 ✓\n","epoch : 587 iter : 19 (23m 11s) 0.0015  / 1 ✓\n","epoch : 595 iter : 15 (23m 30s) 0.0012  / 0 ✓\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sophisticated-location","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614775038463,"user_tz":-180,"elapsed":1423626,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"56c18d1f-8a18-4197-d4d6-557a00429299"},"source":["total = 0\n","right = 0\n","counter = 0\n","\n","rnn.eval()\n","with torch.no_grad():\n","    for i, data in enumerate(test_loader, 0):\n","        counter = counter + 1\n","        inputs, labels = data[0].to(device), data[1].to(device)  \n","        output = rnn(inputs.float())\n","        guess, guess_i = categoryFromOutput(output)\n","        category = training_subjects[int(labels[0])]\n","        \n","        if guess == category:\n","            right = right + 1\n","\n","\n","print('Accuracy of the network(Модель задания \"с\"):  ',  (100 * right / counter))"],"id":"sophisticated-location","execution_count":79,"outputs":[{"output_type":"stream","text":["Accuracy of the network(Модель задания \"с\"):   58.92857142857143\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"enclosed-auditor"},"source":["Увеличение скрытых слоев в модели нейросети улучшает точность."],"id":"enclosed-auditor"},{"cell_type":"markdown","metadata":{"id":"certified-nightmare"},"source":["#### d. Сгенерировать другой датасет с меньшим количеством “кадров” в серии и сравнить улучшилось или ухудшилось качество предсказания. Провести несколько таких итераций, дать свою оценку уменьшению и увеличению кадров, назвать оптимальное, на ваш взгляд, их количество. Желательно сделать так, чтобы длина последовательности передавалась как атрибут класса."],"id":"certified-nightmare"},{"cell_type":"code","metadata":{"id":"political-keyboard","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614776751636,"user_tz":-180,"elapsed":15054,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"a1bccc04-a538-432c-bb8c-2feaee04304d"},"source":["dataset = Generate_Dataset(data_path=data_path, broken_files_path=broken_files_path, \n","                           training_classes=training_classes,num_joint = 25, \n","                           max_frame = 400, transform=None)"],"id":"political-keyboard","execution_count":85,"outputs":[{"output_type":"stream","text":["action classes:  {23: 0, 1: 1, 17: 2, 5: 3, 32: 4, 21: 5, 10: 6, 22: 7, 8: 8, 27: 9}\n","action files:  {23: 120, 1: 120, 17: 120, 5: 120, 32: 120, 21: 120, 10: 120, 22: 120, 8: 120, 27: 120}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MwnVvJtG2e1_","executionInfo":{"status":"ok","timestamp":1614776751639,"user_tz":-180,"elapsed":14564,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}}},"source":["train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.75*len(dataset)),\r\n","                                                                      len(dataset) - int(0.75*len(dataset))])\r\n","train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\r\n","test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=True)"],"id":"MwnVvJtG2e1_","execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqWD2d7628le","executionInfo":{"status":"ok","timestamp":1614776751640,"user_tz":-180,"elapsed":14221,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"fa5696d3-8977-43f7-e06d-ed510bc1bf6b"},"source":["rnn = LSTM_net(n_joints, n_hidden, n_categories, n_layer)\r\n","rnn.to(device)"],"id":"yqWD2d7628le","execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LSTM_net(\n","  (lstm): LSTM(75, 512, num_layers=2, batch_first=True)\n","  (dr): Dropout2d(p=0.1, inplace=False)\n","  (fc): Linear(in_features=512, out_features=28, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BwJu8ipY2pI-","executionInfo":{"status":"ok","timestamp":1614778200344,"user_tz":-180,"elapsed":1462589,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"79c5a37e-abf9-4f7b-8aac-f94ca963ed32"},"source":["criterion = nn.CrossEntropyLoss()\r\n","learning_rate = 0.0007\r\n","optimizer = optim.SGD(rnn.parameters(), lr=learning_rate, momentum=0.9)\r\n","\r\n","all_losses = []\r\n","start = time.time()\r\n","counter = 0\r\n","for epoch in range(600):  \r\n","    current_loss = 0\r\n","    running_loss = 0.0\r\n","    for i, data in enumerate(train_loader, 0):\r\n","        \r\n","        inputs, labels = data[0].to(device), data[1].to(device)\r\n","        optimizer.zero_grad()\r\n","    \r\n","        output = rnn(inputs.float())\r\n","        labels = labels.type(torch.LongTensor).to(device)\r\n","        loss = criterion(output, labels)\r\n","        loss.backward()\r\n","        optimizer.step() \r\n","\r\n","\r\n","        current_loss += loss.item()\r\n","        category = training_subjects[int(labels[0])]\r\n","\r\n","        if counter % 500 == 0:\r\n","            guess, guess_i = categoryFromOutput(output)\r\n","            correct = '✓' if guess == category else '✗ (%s)' % category\r\n","            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\r\n","\r\n","        \r\n","        counter = counter + 1\r\n","    if counter % 100 == 0:\r\n","        all_losses.append(current_loss / 25)\r\n","        current_loss = 0"],"id":"BwJu8ipY2pI-","execution_count":88,"outputs":[{"output_type":"stream","text":["epoch : 0 iter : 0 (0m 0s) 3.3312  / 24 ✗ (7)\n","epoch : 7 iter : 59 (0m 19s) 2.3556  / 4 ✗ (6)\n","epoch : 15 iter : 55 (0m 38s) 2.3051  / 1 ✗ (4)\n","epoch : 23 iter : 51 (0m 58s) 2.2868  / 4 ✓\n","epoch : 31 iter : 47 (1m 17s) 2.3340  / 7 ✗ (6)\n","epoch : 39 iter : 43 (1m 36s) 2.0509  / 8 ✗ (4)\n","epoch : 47 iter : 39 (1m 55s) 1.8357  / 6 ✗ (1)\n","epoch : 55 iter : 35 (2m 14s) 1.8927  / 5 ✗ (6)\n","epoch : 63 iter : 31 (2m 32s) 1.7919  / 3 ✓\n","epoch : 71 iter : 27 (2m 52s) 1.7007  / 3 ✗ (5)\n","epoch : 79 iter : 23 (3m 11s) 1.9688  / 8 ✗ (0)\n","epoch : 87 iter : 19 (3m 30s) 1.6872  / 9 ✓\n","epoch : 95 iter : 15 (3m 48s) 1.4433  / 4 ✗ (6)\n","epoch : 103 iter : 11 (4m 7s) 1.9405  / 8 ✓\n","epoch : 111 iter : 7 (4m 27s) 1.5621  / 2 ✗ (3)\n","epoch : 119 iter : 3 (4m 47s) 1.4994  / 8 ✓\n","epoch : 126 iter : 62 (5m 6s) 1.6571  / 2 ✓\n","epoch : 134 iter : 58 (5m 26s) 1.4114  / 5 ✓\n","epoch : 142 iter : 54 (5m 45s) 1.7701  / 8 ✓\n","epoch : 150 iter : 50 (6m 4s) 1.4267  / 9 ✓\n","epoch : 158 iter : 46 (6m 23s) 1.4852  / 3 ✓\n","epoch : 166 iter : 42 (6m 43s) 1.1498  / 8 ✓\n","epoch : 174 iter : 38 (7m 2s) 1.2420  / 1 ✓\n","epoch : 182 iter : 34 (7m 21s) 1.1891  / 9 ✗ (2)\n","epoch : 190 iter : 30 (7m 40s) 1.2322  / 2 ✓\n","epoch : 198 iter : 26 (8m 0s) 1.4529  / 3 ✗ (9)\n","epoch : 206 iter : 22 (8m 19s) 1.3764  / 0 ✗ (4)\n","epoch : 214 iter : 18 (8m 39s) 1.0328  / 3 ✓\n","epoch : 222 iter : 14 (8m 59s) 1.3283  / 7 ✓\n","epoch : 230 iter : 10 (9m 19s) 0.9410  / 6 ✓\n","epoch : 238 iter : 6 (9m 39s) 0.8813  / 4 ✓\n","epoch : 246 iter : 2 (9m 58s) 0.6806  / 3 ✓\n","epoch : 253 iter : 61 (10m 18s) 1.1477  / 1 ✗ (4)\n","epoch : 261 iter : 57 (10m 37s) 0.7216  / 5 ✗ (1)\n","epoch : 269 iter : 53 (10m 56s) 0.6247  / 5 ✓\n","epoch : 277 iter : 49 (11m 16s) 0.7639  / 4 ✓\n","epoch : 285 iter : 45 (11m 35s) 0.8164  / 1 ✓\n","epoch : 293 iter : 41 (11m 54s) 0.5190  / 6 ✓\n","epoch : 301 iter : 37 (12m 13s) 0.4142  / 5 ✓\n","epoch : 309 iter : 33 (12m 32s) 0.1303  / 2 ✓\n","epoch : 317 iter : 29 (12m 51s) 0.4025  / 8 ✓\n","epoch : 325 iter : 25 (13m 10s) 0.3319  / 7 ✓\n","epoch : 333 iter : 21 (13m 29s) 0.4041  / 5 ✓\n","epoch : 341 iter : 17 (13m 49s) 0.5875  / 5 ✓\n","epoch : 349 iter : 13 (14m 8s) 0.0736  / 2 ✓\n","epoch : 357 iter : 9 (14m 27s) 0.0451  / 7 ✓\n","epoch : 365 iter : 5 (14m 46s) 0.0112  / 3 ✓\n","epoch : 373 iter : 1 (15m 5s) 0.1491  / 0 ✓\n","epoch : 380 iter : 60 (15m 24s) 0.0104  / 8 ✓\n","epoch : 388 iter : 56 (15m 43s) 0.0082  / 5 ✓\n","epoch : 396 iter : 52 (16m 2s) 0.0062  / 2 ✓\n","epoch : 404 iter : 48 (16m 21s) 0.1297  / 9 ✓\n","epoch : 412 iter : 44 (16m 40s) 0.0694  / 5 ✓\n","epoch : 420 iter : 40 (16m 59s) 0.0041  / 2 ✓\n","epoch : 428 iter : 36 (17m 18s) 0.0017  / 9 ✓\n","epoch : 436 iter : 32 (17m 37s) 0.0027  / 9 ✓\n","epoch : 444 iter : 28 (17m 56s) 0.0021  / 4 ✓\n","epoch : 452 iter : 24 (18m 15s) 0.0028  / 5 ✓\n","epoch : 460 iter : 20 (18m 34s) 0.1176  / 4 ✓\n","epoch : 468 iter : 16 (18m 53s) 0.0027  / 7 ✓\n","epoch : 476 iter : 12 (19m 12s) 0.0046  / 4 ✓\n","epoch : 484 iter : 8 (19m 31s) 0.0022  / 5 ✓\n","epoch : 492 iter : 4 (19m 50s) 0.0014  / 6 ✓\n","epoch : 500 iter : 0 (20m 9s) 0.0019  / 4 ✓\n","epoch : 507 iter : 59 (20m 28s) 0.1269  / 4 ✓\n","epoch : 515 iter : 55 (20m 47s) 0.0019  / 8 ✓\n","epoch : 523 iter : 51 (21m 6s) 0.0017  / 1 ✓\n","epoch : 531 iter : 47 (21m 25s) 0.0015  / 5 ✓\n","epoch : 539 iter : 43 (21m 44s) 0.1210  / 2 ✗ (6)\n","epoch : 547 iter : 39 (22m 3s) 0.0007  / 7 ✓\n","epoch : 555 iter : 35 (22m 22s) 0.0018  / 2 ✓\n","epoch : 563 iter : 31 (22m 41s) 0.0727  / 7 ✓\n","epoch : 571 iter : 27 (23m 0s) 0.0010  / 7 ✓\n","epoch : 579 iter : 23 (23m 19s) 0.0012  / 9 ✓\n","epoch : 587 iter : 19 (23m 38s) 0.0010  / 4 ✓\n","epoch : 595 iter : 15 (23m 57s) 0.0004  / 3 ✓\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZntbRDC72q8Q","executionInfo":{"status":"ok","timestamp":1614778201705,"user_tz":-180,"elapsed":1463089,"user":{"displayName":"Alexey Tankov","photoUrl":"","userId":"01729535101672247421"}},"outputId":"20ce3d2d-50ba-44e2-bb80-adeb5f315144"},"source":["total = 0\r\n","right = 0\r\n","counter = 0\r\n","\r\n","rnn.eval()\r\n","with torch.no_grad():\r\n","    for i, data in enumerate(test_loader, 0):\r\n","        counter = counter + 1\r\n","        inputs, labels = data[0].to(device), data[1].to(device)  \r\n","        output = rnn(inputs.float())\r\n","        guess, guess_i = categoryFromOutput(output)\r\n","        category = training_subjects[int(labels[0])]\r\n","        \r\n","        if guess == category:\r\n","            right = right + 1\r\n","\r\n","\r\n","print('Accuracy of the network(Модель задания \"d\"):  ',  (100 * right / counter))"],"id":"ZntbRDC72q8Q","execution_count":89,"outputs":[{"output_type":"stream","text":["Accuracy of the network(Модель задания \"d\"):   57.73809523809524\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zM0E3EqoMJ2V"},"source":["Accuracy of the network(Модель задания \"d\" при max_frame = 200):   60.714285714285715  \r\n","Accuracy of the network(Модель задания \"d\" при max_frame = 400):   57.73809523809524"],"id":"zM0E3EqoMJ2V"},{"cell_type":"markdown","metadata":{"id":"cross-sixth"},"source":["2.\tДополнительное задание:  \n","a.\thttp://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption - 2075259 measurements gathered in a house located in Sceaux (7km of Paris, France) between December 2006 and November 2010 (47 months). Проделайте весь путь подготовки данных, создания датасета, разделения и обучения модели самостоятельно. Предсказывать нужно Global_active_power. Обратите внимание, что здесь задача регрессии, а не классификации, т.е. модель нужно изменить.  "],"id":"cross-sixth"},{"cell_type":"code","metadata":{"id":"widespread-collectible"},"source":[""],"id":"widespread-collectible","execution_count":null,"outputs":[]}]}